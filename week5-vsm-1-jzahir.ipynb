{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 - Vector Space Model (VSM) and Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the next weeks, we are going to re-implement Sherin's algorithm and apply it to the text data we've been working on last week! Here's our roadmap:\n",
    "\n",
    "**Week 5 - data cleaning**\n",
    "1. import the data\n",
    "2. clean the data (e.g., remopve stop words, punctuation, etc.)\n",
    "3. build a vocabulary for the dataset\n",
    "4. create chunks of 100 words, with a 25-words overlap\n",
    "5. create a word count matrix, where each chunk of a row and each column represents a word\n",
    "\n",
    "**Week 6 - vectorization and linear algebra**\n",
    "6. Dampen: weight the frequency of words (1 + log[count])\n",
    "7. Scale: Normalize weighted frequency of words\n",
    "8. Direction: compute deviation vectors\n",
    "\n",
    "**Week 7 - Clustering**\n",
    "9. apply different unsupervised machine learning algorithms\n",
    "    * figure out how many clusters we want to keep\n",
    "    * inspect the results of the clustering algorithm\n",
    "\n",
    "**Week 8 - Visualizing the results**\n",
    "10. create visualizations to compare documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in python code, our goal is to recreate the steps above as functions\n",
    "# so that we can just one line to run topic modeling on a list of \n",
    "# documents: \n",
    "def ExtractTopicsVSM(documents, numTopics):\n",
    "    ''' this functions takes in a list of documents (strings), \n",
    "        runs topic modeling (as implemented by Sherin, 2013)\n",
    "        and returns the clustering results, the matrix used \n",
    "        for clustering a visualization '''\n",
    "    \n",
    "    # step 2: clean up the documents\n",
    "    documents = clean_list_of_documents(documents)\n",
    "    \n",
    "    # step 3: let's build the vocabulary of these docs\n",
    "    vocabulary = get_vocabulary(documents)\n",
    "    \n",
    "    # step 4: we build our list of 100-words overlapping fragments\n",
    "    documents = flatten_and_overlap(documents)\n",
    "    \n",
    "    # step 5: we convert the chunks into a matrix\n",
    "    matrix = docs_by_words_matrix(documents, vocabulary)\n",
    "    \n",
    "    # step 6: we weight the frequency of words (count = 1 + log(count))\n",
    "    matrix = one_plus_log_mat(matrix, documents, vocabulary)\n",
    "    \n",
    "    # step 7: we normalize the matrix\n",
    "    matrix = normalize(matrix)\n",
    "    \n",
    "    # step 8: we compute deviation vectors\n",
    "    matrix = transform_deviation_vectors(matrix, documents)\n",
    "    \n",
    "    # step 9: we apply a clustering algorithm to find topics\n",
    "    results_clustering = cluster_matrix(matrix)\n",
    "    \n",
    "    # step 10: we create a visualization of the topics\n",
    "    visualization = visualize_clusters(results_clustering, vocabulary)\n",
    "    \n",
    "    # finally, we return the clustering results, the matrix, and a visualization\n",
    "    return results_clustering, matrix, visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper0.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper1.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper10.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper11.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper12.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper13.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper14.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper15.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper16.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper2.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper3.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper4.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper5.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper6.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper7.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper8.txt\n",
      "C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\paper9.txt\n"
     ]
    }
   ],
   "source": [
    "# 1) using glob, find all the text files in the \"Papers\" folder\n",
    "# Hint: refer to last week's notebook\n",
    "\n",
    "import glob \n",
    "\n",
    "for filename in glob.glob(r'C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\*.txt'):\n",
    "    print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) get all the data from the text files into the \"documents\" list\n",
    "# P.S. make sure you use the 'utf-8' encoding\n",
    "documents = []\n",
    "\n",
    "for paper in glob.glob(r'C:\\Users\\Jazib Zahir\\Documents\\GitHub\\S435-Week5\\week5-vsm-1-jzahir\\Papers\\*.txt'):\n",
    "    f = open(filename, \"r\", encoding= \"utf-8\")\n",
    "    x = f.readlines()\n",
    "    documents.append(x)\n",
    "    \n",
    "len(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['79\\n', '\\n', '\\x0cpredicting short- and long-term vocabulary learning via\\n', 'semantic features of partial word knowledge\\n', 'sungjin nam\\n', '\\n', 'school of information\\n', 'university of michigan\\n', 'ann arbor, mi 48109\\n', '\\n', 'sjnam@umich.edu\\n', '\\n', 'gwen frishkoff\\n', '\\n', 'kevyn collins-thompson\\n', '\\n', 'gfrishkoff@gmail.com\\n', '\\n', 'kevynct@umich.edu\\n', '\\n', 'department of psychology\\n', 'university of oregon\\n', 'eugene, or 97403\\n', '\\n', 'abstract\\n', '\\n', 'we show how the novel use of a semantic representation\\n', 'based on osgood’s semantic differential scales can lead to\\n', 'effective features in predicting short- and long-term learning\\n', 'in students using a vocabulary learning system. previous\\n', 'studies in students’ intermediate knowledge states during\\n', 'vocabulary acquisition did not provide much information\\n', 'on which semantic knowledge students gained during word\\n', 'learning practice. moreover, these studies relied on human\\n', 'ratings to evaluate the students’ responses. to solve this\\n', 'problem, we propose a semantic representation for words\\n', 'based on osgood’s semantic decomposition of vocabulary\\n', '[16]. to demonstrate our method can effectively represent\\n', 'students’ knowledge in vocabulary acquisition, we build\\n', 'models for predicting the student’s short-term vocabulary\\n', 'acquisition and long-term retention. we compare the\\n', 'effectiveness of our osgood-based semantic representation to\\n', 'that provided by word2vec neural word embedding [13], and\\n', 'find that prediction models using features based on osgood\\n', 'scale-based scores (osg) perform better than the baseline\\n', 'and are comparable in accuracy to those using word2vec\\n', 'score-based models (w2v). by using more interpretable\\n', 'osgood-based scales, our study results can help with better\\n', 'understanding of students’ ongoing learning states and\\n', 'designing personalized learning systems that can address an\\n', 'individual’s weak points in vocabulary acquisition.\\n', '\\n', 'keywords\\n', '\\n', 'vocabulary learning, semantic similarity, prediction model,\\n', 'intelligent tutoring system\\n', '\\n', '1. introduction\\n', '\\n', 'studies of word learning have shown that knowledge of\\n', 'individual words is typically not all-or-nothing. rather,\\n', 'people acquire varying degrees of knowledge of many words\\n', 'incrementally over time, by exposure to them in context [9].\\n', 'this is especially true for so-called “academic” words that are\\n', 'less common and more abstract — e.g., pontificate, probity,\\n', 'or assiduous [7]. binary representations and measures model\\n', 'word knowledge simply as correct or incorrect on a particular\\n', '\\n', 'school of information\\n', 'university of michigan\\n', 'ann arbor, mi 48109\\n', '\\n', 'item (word), but in reality, a student’s knowledge level may\\n', 'reside between these two extremes. thus, previous studies of\\n', 'vocabulary acquisition have suggested that students’ partial\\n', 'knowledge be modeled using a representation that adding an\\n', 'additional label corresponding to an intermediate knowledge\\n', 'state [6] or further, in terms of continuous metrics for\\n', 'semantic similarity [3].\\n', 'in addition, there are multiple dimensions to a word’s\\n', 'meaning [16]. measuring a student’s partial knowledge on\\n', 'a single scale may only provide abstract information about\\n', 'the student’s general answer quality and not give enough\\n', 'information to specify which dimensions of word knowledge\\n', 'a student already has learned or needs to improve. in order\\n', 'to achieve detailed understanding of a student’s learning\\n', 'state, online learning systems should be able to capture\\n', 'a student’s “learning trajectory” that tracks their partial\\n', 'knowledge on a particular item over time, over multiple\\n', 'dimensions of meaning in a multidimensional semantic\\n', 'representation.\\n', 'hence, multidimensional representations of word knowledge\\n', 'can be an important element for building an effective\\n', 'intelligent tutoring system (its) for reading and language.\\n', 'maintaining a fine-grained semantic representation of a\\n', 'student’s degree of word knowledge can be helpful for\\n', 'the its to design more engaging instructional content,\\n', 'more helpful personalized feedback, and more sensitive\\n', 'assessments [17, 19]. selecting semantic representations\\n', 'to model, understand, and predict learning outcomes is\\n', 'important to designing a more effective and efficient its.\\n', 'in this paper, we explore the use of multidimensional\\n', 'semantic word representations for modeling and predicting\\n', 'short- and long-term learning outcomes in a vocabulary\\n', 'tutoring system.\\n', 'our approach derives predictive\\n', 'features using a novel application of existing methods in\\n', 'cognitive psychology combined with methods from natural\\n', 'language processing (nlp). first, we introduce a new\\n', 'multidimensional representation of a word based on the\\n', 'osgood semantic differential [16], an empirically based,\\n', 'cognitive framework that uses a small number of scales\\n', 'to represent latent components of word meaning. we\\n', 'compare the effectiveness of model features based on this\\n', 'osgood-based representation to features based on a different\\n', 'representation, the widely-used word2vec word embedding\\n', '[13]. second, we evaluate our prediction models using\\n', 'data from a meaning-generation task that was conducted\\n', 'during a computer-based intervention. our study results\\n', 'demonstrate how similarity-based metrics based on rich80\\n', '\\n', '\\x0csemantic representation can be used to automatically\\n', 'evaluate specific components of word knowledge, track\\n', 'changes in the student’s knowledge toward the correct\\n', 'meaning, and compute a rich set of features for use in\\n', 'predicting short- and long-term learning outcomes. our\\n', 'methods could support advances in real-time, adaptive\\n', 'support for word semantic learning, resulting in more\\n', 'effective personalized learning systems.\\n', '\\n', 'semantic representation & the osgood framework.\\n', 'to quantify the semantic characteristics of a student’s\\n', 'intermediate knowledge of vocabulary, this paper uses a\\n', '“spatial analogue” for capturing semantic characteristics of\\n', 'words. in [16], osgood investigated how the meaning of\\n', 'a word can be represented by a series of general semantic\\n', 'scales. by using these scales, osgood suggested that the\\n', 'meanings of any word can be projected and explored in a\\n', 'continuous semantic space.\\n', '\\n', '2.\\n', '\\n', 'osgood asked human raters to evaluate a set of words using a\\n', 'large number of scales (e.g., tall-short, fat-thin, heavy-light)\\n', 'and captured the semantic representation of a word [16].\\n', 'respondents gave likert ratings, which indicated whether\\n', 'they thought that a word meaning was closer to one extreme\\n', '(-3) or the other (+3), or basically irrelevant (0). a principal\\n', 'components analysis (pca) was used to represent the latent\\n', 'semantic features that can explain the patterns of response\\n', 'to individual words within this task.\\n', '\\n', 'related work\\n', '\\n', 'the present study is informed by three areas of research:\\n', '(1) studies of partial word knowledge; (2) the osgood\\n', 'framework for multiple dimensions of word meaning, and (3)\\n', 'computational methods for estimating semantic similarity.\\n', 'partial word knowledge. the concept of partial word\\n', 'knowledge has interested vocabulary researchers for several\\n', 'decades, particularly in the learning and instruction of “tier\\n', '2” words [20]. tier 2 words are low-frequency and typically\\n', 'have complex (multiple, nuanced) meanings. by nature,\\n', 'they are rarely learned through “one-shot” learning or direct\\n', 'definition. instead, they are learned partially and gaps are\\n', 'filled in over time.\\n', 'words in this intermediate state, neither novel nor fully\\n', 'known, are sometimes called “frontier words” [5]. durso\\n', 'and shore operationalized the frontier word as a word the\\n', 'student had seen previously but was not actively using it [6].\\n', 'based on this definition, the student may have had implicit\\n', 'memory of frontier words, such as general information like\\n', 'whether the word indicates a good or bad situation or refers\\n', 'a person or an action. they discovered that students are\\n', 'more familiar with frontier words than other types of words\\n', 'in terms of their sounds and orthographic characteristics [6].\\n', 'this previous work suggested that the concept of frontier\\n', 'words can be used to represent a student’s partial knowledge\\n', 'states in a vocabulary acquisition task [5, 6].\\n', 'in some studies, partial word knowledge has been\\n', 'represented using simple, categorical labels, e.g., multiplechoice tests that include “partially correct” response options,\\n', 'as well as a single “best” (correct) response. in other studies,\\n', 'the student is presented with a word and is asked to say\\n', 'what it means [1]. the definition is given partial credit\\n', 'if it reflects knowledge that is partial or incomplete. for\\n', 'example, a student may recognize that the word probity\\n', 'has a positive connotation, even if she cannot give a\\n', 'complete definition. however, single categorical or scorebased indicators may not explain which specific aspects of\\n', 'vocabulary knowledge the student is missing. moreover,\\n', 'these studies relied on human ratings to evaluate students’\\n', 'responses for unknown words [6]. although widely used\\n', 'in psychometric and psycholinguistic studies [4, 16], hiring\\n', 'human raters is expensive and may not be done in real time\\n', 'during students’ interaction with the tutoring system.\\n', 'to address these problems, we propose a data-driven method\\n', 'that can automatically extract semantic characteristics of\\n', 'a word based on a set of relatively simple, interpretable\\n', 'scales. the method benefits from existing findings in\\n', 'cognitive psychology and natural language processing. in\\n', 'the following sections, we illustrate more details of related\\n', 'findings and how they can be used in an intelligent tutoring\\n', 'system setting.\\n', '\\n', 'in our study, we suggest a method that can automatically\\n', 'extract similar semantic information that can project a word\\n', 'into a multidimensional semantic space. by using semantic\\n', 'scales selected from [16], we verify if such representation of\\n', 'semantic attributes of words is useful for predicting students’\\n', 'short- and long-term learning.\\n', 'semantic similarity measures. studies in nlp have\\n', 'suggested methods to automatically evaluate the semantic\\n', 'association between two words. for example, markov\\n', 'estimation of semantic association (mesa) [3, 9] can\\n', 'estimate the similarity between words from a random walk\\n', 'model over a synonym network such as wordnet [14]. other\\n', 'methods like latent semantic analysis (lsa) are based on\\n', 'co-occurrence of the word in a document corpus. in lsa,\\n', 'semantic similarity between words is determined by using\\n', 'a cosine similarity measure, derived from a sparse matrix\\n', 'constructed from unique words and paragraphs containing\\n', 'the words [10].\\n', 'for this paper, we use word2vec [13], a widely used word\\n', 'embedding method, to calculate the semantic similarity\\n', 'between words. word2vec’s technique [11] transforms the\\n', 'semantic context, such as proximity between words, into a\\n', 'numeric vector space. in this way, linguistic regularities\\n', 'and patterns are encoded into linear translations. for\\n', 'example, using outputs from word2vec, relationships\\n', 'between words can be estimated by simple operations on\\n', 'their corresponding vectors, e.g., madrid - spain + france\\n', '= paris, or germany + capital = berlin [13].\\n', 'measures from these computational semantic similarity tools\\n', 'are powerful because they can provide an automated method\\n', 'for evaluation of partial word knowledge. however, they\\n', 'typically produce a single measure (e.g., cosine similarity or\\n', 'euclidean distance), representing semantic similarity as a\\n', 'one-dimensional construct. with such a measure, it is not\\n', 'possible to determine represent partial semantic knowledge\\n', 'and changes in knowledge of latent semantic features as\\n', 'word knowledge progresses from unknown to frontier to\\n', 'fully known. in following sections, we describe how we\\n', 'address this problem, using novel methods to to estimate\\n', 'the contribution of osgood semantic features to individual\\n', 'word meanings.81\\n', '\\n', '\\x0c2.1\\n', '\\n', 'overview of the study\\n', '\\n', 'based on findings from existing studies, this study will\\n', 'suggest an automatized method for evaluating students’\\n', 'partial knowledge of vocabulary that can be used to predict\\n', 'students’ short-term vocabulary acquisition and long-term\\n', 'retention. to investigate this problem, we will answer the\\n', 'following research questions with this paper.\\n', 'the first research question (rq1): can semantic similarity\\n', 'scores from word2vec be used to predict students’ shortterm learning and long-term retention? previous studies in\\n', 'vocabulary tutoring systems tend to focus on how different\\n', 'experimental conditions, such as different spacing between\\n', 'question items [18], difficulty levels [17], and systematic\\n', 'feedback [7], affect students’ short-term learning. this study\\n', 'will answer how computationally estimated trial-by-trial\\n', 'scores in a vocabulary tutoring system can be used to predict\\n', 'students’ short-term learning and long-term retention.\\n', 'rq2: compared to using regular word2vec scores, how does\\n', 'the model using osgood’s semantic scales [16] as features\\n', 'perform for immediate and delayed learning prediction\\n', 'tasks? as described in the previous section, the initial\\n', 'outcome from word2vec returns hundreds of semantic\\n', 'dimensions to represent the semantic characteristics of\\n', 'a word. summary statistics for comparing such highdimensional vectors, such as cosine similarity or euclidean\\n', 'distance, only provide the overall similarity between words.\\n', 'if measures from osgood scales work in a similar level\\n', 'to models using regular word2vec scores for predicting\\n', 'students’ learning outcomes, we can argue that it can\\n', 'be an effective method for representing students’ partial\\n', 'knowledge of vocabulary.\\n', '\\n', '3. method\\n', '3.1 word learning study\\n', '\\n', 'this study used a vocabulary tutoring system called\\n', 'dynamic support of contextual vocabulary acquisition\\n', 'for reading (dscovar) [8]). dscovar aims to support\\n', 'efficient and effective learning vocabulary in context. all\\n', 'participants accessed dscovar in a classroom-setting\\n', 'environment by using chromebook devices or the school’s\\n', 'computer lab in the presence of other students.\\n', '\\n', '3.1.1\\n', '\\n', 'study participants\\n', '\\n', 'participants included 280 middle school students (6th to\\n', '8th grade) from multiple schools, including children from\\n', 'diverse socio-economic and educational backgrounds. table\\n', '1 provides a summary of student demographics, including\\n', 'location (p1 or p2), age and grade level, sex. location p1 is\\n', 'a laboratory school affiliated with a large urban university in\\n', 'the northeastern united states. students from location p1\\n', 'were generally of high socio-economic status (e.g., children\\n', 'of university faculty and staff). location p2 includes three\\n', 'public middle schools in a southern metropolitan area of the\\n', 'united states. all students from location p2 qualified for\\n', 'free or reduced lunch. the study included a broad range of\\n', 'students so that the results of this analysis were more likely\\n', 'to generalize to future samples.\\n', '\\n', '3.1.2\\n', '\\n', 'study materials\\n', '\\n', 'dscovar presented students with 60 sat-level english\\n', 'words (also known as tier 2 words). these “target words,”\\n', 'lesser-known words that the students are going to learn,\\n', '\\n', 'table 1: the number of participants by grade and\\n', 'gender\\n', 'group\\n', 'p1\\n', 'p2\\n', '\\n', '6th grade\\n', 'girl\\n', 'boy\\n', '16\\n', '28\\n', '53\\n', '51\\n', '\\n', '7th grade\\n', 'girl\\n', 'boy\\n', '19\\n', '23\\n', '12\\n', '6\\n', '\\n', '8th grade\\n', 'girl\\n', 'boy\\n', '18\\n', '13\\n', '21\\n', '20\\n', '\\n', 'were balanced between different parts of speech, including 20\\n', 'adjectives, 20 nouns, and 20 verbs. based on previous works,\\n', 'we expected that students would have varying degrees of\\n', 'familiarity with the words at pre-test, but that most words\\n', 'would be either completely novel (“unknown”) or somewhat\\n', 'familiar (“partially known”) [8, 15]. this selection of\\n', 'materials ensured that there would be variability in word\\n', 'knowledge across students for each word and across words\\n', 'for each student.\\n', 'in dscovar, students learned how to infer the meaning\\n', 'of an unknown word in a sentence by using surrounding\\n', 'contextual information. having more information in a\\n', 'sentence (i.e., a sentence with a high degree of contextual\\n', 'constraint) can decrease the uncertainty of inference. in\\n', 'this study, the degree of sentence constraint was determined\\n', 'using standard cloze testing methods: quantifying the\\n', 'diversity of responses from 30 human judges when the target\\n', 'word is left as a fill-in-the-blank question.\\n', '\\n', '3.1.3\\n', '\\n', 'study protocol\\n', '\\n', 'the word learning study comprised four parts: (1) a pretest, which was used to estimate baseline knowledge of\\n', 'words, (2) a training session, where learners were exposed to\\n', 'words in meaningful contexts, (3) an immediate post-test,\\n', 'and (4) a delayed post-test, which occurred approximately\\n', 'one week after training.\\n', 'pre-test. the pre-test session was designed to measure\\n', 'the students’ prior knowledge of the target words. for\\n', 'each target word, students were asked to answer two types\\n', 'of questions: familiarity-rating questions and synonym\\n', 'selection questions. in familiarity rating questions, students\\n', 'provided their self-rated familiarity levels (unknown, known,\\n', 'and familiar) for presented target words. in synonymselection questions, students were asked to select a synonym\\n', 'word for the given target word from five multiple choice\\n', 'options. the outcome from synonym-selection questions\\n', 'provided more objective measures for students’ prior domain\\n', 'knowledge of target words.\\n', 'training. approximately one week after the pre-test\\n', 'session, students participated in the training. during\\n', 'training, students learned strategies to infer the meaning\\n', 'of an unknown word in a sentence by using surrounding\\n', 'contextual information.\\n', 'a training session consisted of two parts: an instruction\\n', 'video and practice questions. in the instruction video,\\n', 'students saw an animated movie clip about how to identify\\n', 'and use contextual information from the sentence to infer\\n', 'the meaning of an unknown word. in the practice question\\n', 'part, students could exercise the skill that they learned from\\n', 'the video. dscovar provided sentences that included a\\n', 'target word with different levels of surrounding contextual\\n', 'information. the amount of contextual information for\\n', 'each sentence was determined by external crowd workers\\n', '(details described in section 3.1.2). in the practice question\\n', 'part, each target word was presented four times within82\\n', '\\n', '\\x0cdifferent sentences. students were asked to type a synonym\\n', 'of the target word, which was presented in the sentence as\\n', 'underlined and bold. over two weeks, students participated\\n', 'in two training sessions with a week’s gap between them.\\n', 'each training session contained the instruction video and\\n', 'practice questions for 30 target words. an immediate posttest session followed right after each training session.\\n', 'figure 1: an example of a training session question.\\n', 'in this example, the target word is “education” with\\n', 'a feedback message for a high-accuracy response.\\n', '\\n', 'figure 2: ten semantic scales used for projecting\\n', 'target words and responses [16].\\n', '• bad – good\\n', '\\n', '• complex – simple\\n', '\\n', '• passive – active\\n', '\\n', '• fast – slow\\n', '\\n', '• powerful – helpless\\n', '\\n', '• noisy – quiet\\n', '\\n', '• big – small\\n', '\\n', '• new – old\\n', '\\n', '• helpful – harmful\\n', '\\n', '• healthy – sick\\n', '\\n', 'end. the word’s relationship with each semantic anchor can\\n', 'be automatically measured from its semantic similarity with\\n', 'these exemplar semantic elements.\\n', '\\n', '3.2.2\\n', '\\n', 'students were randomly selected to experience different\\n', 'instruction video conditions (full instruction video vs.\\n', 'restricted instruction video). additionally, various difficulty\\n', 'level conditions and feedback conditions (e.g., dscovar\\n', 'provides a feedback message to the student based on answer\\n', 'accuracy vs. no feedback) were tested within the same\\n', 'student. however, in this study, we focused on data\\n', 'from students who experienced a full instruction video\\n', 'and repeating difficulty conditions. repeating difficulty\\n', 'conditions included questions with all high or medium\\n', 'contextual constraint levels. by doing so, we wanted to\\n', 'minimize the impact from various experimental conditions\\n', 'for analyzing post-test outcomes. moreover, we filtered out\\n', 'response sequences that did not include all four responses\\n', 'for the target word. as a result, we analyzed 818 response\\n', 'sequences from 7,425 items in total.\\n', 'immediate and delayed post-test. the immediate\\n', 'post-test occurred right after the students finished the\\n', 'training; the delayed post-test was conducted one week later.\\n', 'data collected during the immediate and delayed posttests were used to estimate short-and long-term learning,\\n', 'respectively. test items were identical to those in the pretest\\n', 'session, except for item order, which varied across tests. for\\n', 'analysis of the delayed post-test data, we only used the data\\n', 'from target words for which the student provided a correct\\n', 'answer in the earlier, immediate post-test session. as a\\n', 'result, 449 response sequences were analyzed for predicting\\n', 'the long-term retention.\\n', '\\n', '3.2\\n', '\\n', 'semantic score-based features\\n', '\\n', 'we now describe the semantic features tested in our\\n', 'prediction models.\\n', '\\n', '3.2.1\\n', '\\n', 'semantic scales\\n', '\\n', 'for this study, we used semantic scales from osgood’s study\\n', '[16]. ten scales were selected by a cognitive psychologist as\\n', 'being considered semantic attributes that can be detected\\n', 'during word learning (figure 2). each semantic scale\\n', 'consists of pairs of semantic attributes. for example, the\\n', 'bad–good scale can show how the meaning of a word can\\n', 'be projected on a scale with bad and good located at either\\n', '\\n', 'basic semantic distance scores\\n', '\\n', 'to extract meaningful semantic information, we have\\n', 'applied the following measures that can be used to explain\\n', 'various characteristics of student responses for different\\n', 'target words. in this study, we used a pre-trained model\\n', 'for word2vec,1 built based on the google news corpus\\n', '(100 billion tokens with 3 million unique vocabularies,\\n', 'using a negative sampling algorithm), to measure semantic\\n', 'similarity between words. the output of the pre-trained\\n', 'word2vec model contained a numeric vector with 300\\n', 'hundred dimensions.\\n', 'first, we calculated the relationship between word pairs (i.e.,\\n', 'a single student response and the target word, or a pair of\\n', 'responses) in both the regular word2vec (w2v) score and\\n', 'the osgood semantic scale (osg) score. in the w2v score,\\n', 'the semantic relationship between words was represented\\n', 'with a cosine similarity between word vectors:\\n', 'dw2v (w1 , w2 ) = 1 − |sim(v (w1 ), v (w2 ))|.\\n', '\\n', '(1)\\n', '\\n', 'in this equation, the function v returned the vectorized\\n', 'representation of the word (w1 or w2 ) from the pre-trained\\n', 'word2vec model. by calculating the cosine similarity\\n', 'between two vectors (a cosine similarity function is noted\\n', 'as sim), we could extract a single numeric similarity score\\n', 'between two words. this score was converted into a\\n', 'distance-like score by taking the absolute value of the cosine\\n', 'similarity score and subtracting from one.\\n', 'for the osg score, we extracted two different types of\\n', 'scores: a non-normalized score and a normalized score. a\\n', 'non-normalized score showed how a word is similar to a\\n', 'single anchor word (e.g., bad or good ) from the osgood scale.\\n', 'non\\n', 'sosg\\n', '(w, ai,j ) = sim(v (w), v (ai,j ))\\n', '\\n', '(2)\\n', '\\n', 'non\\n', 'non\\n', 'non\\n', 'dosg\\n', '(w1 , w2 ; ai,j ) = |sosg\\n', '(w1 , ai,j )| − |sosg\\n', '(w2 , ai,j )| (3)\\n', '\\n', 'in equation 2, ai,j represents a single anchor word (j) in\\n', 'the i-th osgood scale. the similarity between the anchor\\n', 'word and the evaluating word w was calculated with cosine\\n', 'similarity of word2vec outcomes for both words. in a nonnormalized setting, the distance between two words given\\n', 'by a particular anchor word was calculated by the difference\\n', 'of absolute cosine similarity scores (equation 3).\\n', 'the second type of osg score is a normalized score. by\\n', 'using word2vec’s ability to do arithmetical calculation of\\n', '1\\n', 'api and pre-trained model for word2vec was downloaded\\n', 'from this url: https://github.com/3top/word2vec-api83\\n', '\\n', '\\x0cmultiple word vectors, the normalized osg score provided\\n', 'a relative location of the word from two anchor ends of the\\n', 'osgood scale.\\n', 'nrm\\n', 'sosg\\n', '(w, ai ) = sim(v (w), v (ai,1 ) − v (ai,2 ))\\n', 'nrm\\n', 'nrm\\n', 'nrm\\n', 'dosg\\n', '(w1 , w2 ; ai ) = |sosg\\n', '(w1 , ai ) − sosg\\n', '(w2 , ai )|\\n', '\\n', '(4)\\n', '(5)\\n', '\\n', 'in equation 4, the output represents the cosine similarity\\n', 'score between the word w and two anchor words (ai,1\\n', 'and ai,2 ). for example, if the cosine similarity score of\\n', 'nrm\\n', 'sosg\\n', '(w, ai ) is close to -1, it means the word w is close to\\n', 'the first anchor word ai,1 . if the score is close to 1, it is vice\\n', 'versa. in equation 5, the distance between two words was\\n', 'calculated as the absolute value of the difference between\\n', 'two cosine similarity measures.\\n', '\\n', '3.2.3\\n', '\\n', 'deriving predictive features\\n', '\\n', 'based on semantic distance equations explained in the\\n', 'previous section, this section explains examples of predictive\\n', 'features that we used to predict students’ short-term\\n', 'learning and long-term retention.\\n', 'distance between the target word and the\\n', 'response. for regular word2vec score models and osgood\\n', 'scale score models, distance measures between the target\\n', 'word and the response (by using equations 1 and 5) were\\n', 'used to estimate the accuracy of the response to a question.\\n', 'this feature represents the trial-by-trial answer accuracy of\\n', 'a student response. each response sequence for the target\\n', 'word contained four distance scores.\\n', 'difference between responses. another feature that\\n', 'we used in both types of models was the difference between\\n', 'responses. this feature could capture how a student’s\\n', 'current answer is semantically different from the previous\\n', 'response. from each response sequence, we could extract\\n', 'three derivative scores from four responses.\\n', 'convex hull area of responses.\\n', 'alternative to\\n', 'the difference between responses feature, osgood scale\\n', 'models were also tested with the area size of convex hull\\n', 'that can be generated by responses calculated with nonnormalized osgood scale scores (equation 3). for example,\\n', 'for each osgood scale, a non-normalized score provided\\n', 'two-dimensional scores that can be used for geometric\\n', 'representation. by putting the target word in an origin\\n', 'position, a sequence of responses can create a polygon\\n', 'that can represent the semantic area that the student\\n', 'explored with responses. since some response sequences\\n', 'were unable to generate the polygon by including less than\\n', 'three unique responses, we added a small, random noise\\n', 'that uniformly distributed (between −10−4 and 10−4 ) to all\\n', 'response points. additionally, a value of 10−20 was added to\\n', 'all convex hull area output to create a visible lower-bound\\n', 'value.\\n', 'unlike the measure of difference between responses, this\\n', 'feature also considers angles that can be created between\\n', 'responses and the target word. this representation can\\n', 'provide more information than just using difference between\\n', 'responses.\\n', '\\n', '3.3\\n', '\\n', 'modeling\\n', '\\n', 'to predict students’ short-term learning and long-term\\n', 'retention, we used a mixed-effect logistic regression model\\n', '\\n', '(mlr). mlr is a general form of logistic regression model\\n', 'that includes random effect factors to capture variations\\n', 'from repeated measures.\\n', '\\n', '3.3.1\\n', '\\n', 'off-line variables\\n', '\\n', 'off-line variables capture item- or subject-level variances\\n', 'that can be observed repeatedly from the data. in this study,\\n', 'we used multiple off-line variables as random effect factors.\\n', 'first, results from familiarity-rating and synonym-selection\\n', 'questions from the pre-test session were used to include\\n', 'item- and subject-level variances. both variables include\\n', 'information on the student’s prior domain knowledge level\\n', 'for target words. second, the question difficulty condition\\n', 'was considered as an item group level factor. in the analysis,\\n', 'sentences for the target word that were presented to the\\n', 'student contained the same difficulty level, either high or\\n', 'medium contextual constraint levels, over four trials. third,\\n', 'a different experiment group was used as a subject group\\n', 'factor. as described in section 3.1.1, this study contains\\n', 'data from students in different institutions in separate\\n', 'geographic locations. the inclusion of these participant\\n', 'groups in the model can be used to explain different\\n', 'short-term learning outcomes and long-term retention by\\n', 'demographic groups.\\n', '\\n', '3.3.2\\n', '\\n', 'model building\\n', '\\n', 'in this study, we compared the performance of mlr models\\n', 'with four different feature types. first, the baseline model\\n', 'was set to indicate the mlr model’s performance without\\n', 'any fixed effect variables but only with random intercepts.\\n', 'second, the response time model was built to be compared\\n', 'with semantic score-based models. many previous studies\\n', 'have used response time as an important predictor of student\\n', 'engagement and learning [2, 12]. in this study, we used two\\n', 'types of response time variables, the latency for initiating\\n', 'the response and finishing typing the response, as predictive\\n', 'features. both variables were measured in milliseconds over\\n', 'four trials and natural log transformed for the analysis.\\n', 'third, semantic features from regular word2vec scores were\\n', 'used as predictors. this model was built to show how\\n', 'semantic scores from word2vec can be useful for predicting\\n', 'students’ short- and long-term performance in dscovar.\\n', 'lastly, osgood scale-based features were used as predictors.\\n', 'this model was compared with the regular word2vec score\\n', 'model to examine the effectiveness of using osgood scales for\\n', 'evaluating students’ performance in dscovar. for these\\n', 'semantic-score based models, we tested out different types\\n', 'of predictive features that were described in section 3.2.3.\\n', 'all models shared the same random intercept structure\\n', 'that treated each off-line variable as an individual random\\n', 'intercept.\\n', 'for osgood scale models, we also derived reduced-scale\\n', 'models. reduced-scale models were compared with the fullscale model, which uses all ten osgood scales. in this case,\\n', 'using fewer osgood scales can provide easier interpretation\\n', 'of semantic analysis for intelligent tutoring system users.\\n', '\\n', '3.3.3\\n', '\\n', 'model evaluation\\n', '\\n', 'to compare performance between different models, this\\n', 'study used various evaluation metrics, including auc (an\\n', 'area under the curve score from a response operating\\n', 'characteristic (roc) curve), f1 (a harmonic mean of\\n', 'precision and recall), and error rate (a ratio of the number of84\\n', '\\n', '\\x0cmisclassified items over total items). 95% confidence interval\\n', 'of each evaluation metric was calculated from the outcome of\\n', 'a ten-fold cross-validation process repeated over ten times.\\n', 'to select the semantic score-based features for models based\\n', 'on regular word2vec scores and osgood scale scores, we\\n', 'used rankings from each evaluation metric. the model with\\n', 'the highest overall rank (i.e., sum the ranks from auc, f1 ,\\n', 'and error rate, and select the model with the lowest ranksum value) was considered the best-performing model for\\n', 'the score type (i.e., models based on the regular word2vec\\n', 'score or osgood scale score). more details on this process\\n', 'will be illustrated in the next section.\\n', '\\n', '4. results\\n', '4.1 selecting models\\n', '\\n', 'in this section, we selected the best-performing model based\\n', 'on the models’ overall ranks in each evaluation metric. all\\n', 'model parameters were trained in each fold of repeated\\n', 'cross-validation. we calculated 95% confidence intervals for\\n', 'comparison. to calculate the confidence interval of f1 and\\n', 'error rate measures, the maximum (f1 ) and minimum (error\\n', 'rate) scores of each fold were extracted. these maximum\\n', 'and minimum values were derived from applying multiple\\n', 'cutoff points to the mixed-effect regression model.\\n', '\\n', '4.1.1\\n', '\\n', 'predicting immediate learning\\n', '\\n', 'first, we built models that predict the students’ immediate\\n', 'learning from the immediate post-test session.\\n', 'from\\n', 'models based on regular word2vec scores (w2v), the model\\n', 'with the distance between the target and responses and\\n', 'the difference between responses (dist+resp) provided the\\n', 'highest rank from various evaluation metrics (table 2).\\n', 'from models based on osgood scales (osg), the model with\\n', 'the difference between responses (resp) provided the highest\\n', 'rank.\\n', 'the selected w2v model provided significantly better\\n', 'performance than the baseline model. the selected osg\\n', 'model also showed significantly better performance than the\\n', 'baseline model, except for the auc score. the selected\\n', 'w2v model was significantly better than the model using\\n', 'response time features in the auc score and error rates.\\n', 'the selected w2v model showed significantly better\\n', 'performance than the osg model only with the auc score.\\n', 'figure 3 shows that the w2v model has a slightly larger area\\n', 'under the roc curve than the osg model. in the precision\\n', 'and recall curve, the selected w2v model provides more\\n', 'balanced trade-offs between precision and recall measures.\\n', 'the selected osg model outperforms the w2v model in\\n', 'precision only in a very low recall measure range.\\n', '\\n', '4.1.2\\n', '\\n', 'predicting long-term retention\\n', '\\n', 'we also built prediction models to predict the students’\\n', 'long-term retention in the delayed post-test session. in\\n', 'this analysis, a student response was included only when\\n', 'the student provided correct answers to the immediate\\n', 'post-test session questions.\\n', 'among w2v score-based\\n', 'models, the best-performing model contained the same\\n', 'feature types as the immediate post-test results (table 3).\\n', 'by using the distance between the target and responses\\n', 'and difference between responses (dist+resp), the model\\n', '\\n', 'achieved significantly better performance than the baseline\\n', 'model, except for the auc score.\\n', 'for osg models, the model with a convex hull area of\\n', 'responses (chull ) provided the highest overall rank from\\n', 'evaluation metrics (table 3). the results were significantly\\n', 'better than the baseline model, and marginally better than\\n', 'the w2v model. both selected w2v and osg models were\\n', 'marginally better than the response time model, except the\\n', 'error rate of the osg model was significantly better.\\n', 'in figure 3, the selected w2v model slightly outperforms\\n', 'the osg model in mid-range true positive rates, while\\n', 'the osg model performed slightly better in a higher true\\n', 'positive area. precision and recall curves show similar\\n', 'patterns to those we observed from the immediate post-test\\n', 'prediction models. the osg model only outperforms the\\n', 'w2v model in a very low recall value area.\\n', '\\n', '4.1.3 comparing models\\n', 'compared to the selected w2v model in the immediate\\n', 'post-test condition, the selected w2v model in the delayed\\n', 'post-test retention condition showed a significantly lower\\n', 'auc score, marginally higher f1 score, and marginally\\n', 'higher error rate. in terms of osg models, the selected osg\\n', 'model for delayed post-test retention showed a significantly\\n', 'better f1 score and error rates than the selected osg model\\n', 'in the immediate post-test condition. based on these results,\\n', 'we can argue that osgood scale scores can be more useful for\\n', 'predicting student retention in the delayed post-test session\\n', 'than predicting the outcome from the immediate post-test.\\n', 'in terms of selected feature types, the best-performing\\n', 'osg models used features based on the difference between\\n', 'responses (resp) or the convex hull area (chull ) that was\\n', 'created from the relative location of the responses. on the\\n', 'other hand, selected w2v models used both the distance\\n', 'between the target word and responses and difference\\n', 'between responses (dist+resp).\\n', 'when we compared\\n', 'both w2v and osg models using the difference between\\n', 'responses feature, we found that performance is similar in\\n', 'the immediate post-test data. however, the osg model\\n', 'was significantly better in the delayed post-test data. these\\n', 'results show that osgood scale scores can be more useful for\\n', 'representing the relationship among response sequences.\\n', '\\n', '4.2 comparing the osgood scales\\n', '\\n', 'to identify which osgood scales are more helpful than\\n', 'others for predicting students’ performance, we conducted\\n', 'a scale-wise importance analysis. the results from this\\n', 'section reveal which osgood scales are more important than\\n', 'others, and how the performance of prediction models with\\n', 'a reduced number of scales is comparable with the full-scale\\n', 'model.\\n', '\\n', '4.2.1\\n', '\\n', 'identifying more important osgood scales\\n', '\\n', 'in this section, based on the selected osgood score model\\n', 'from section 4.1, we identified the level of contribution for\\n', 'features based on each osgood scale. for example, the\\n', 'selected osg model for predicting the immediate post-test\\n', 'data uses the difference between responses in ten osgood\\n', 'scales as features. in order to diagnose the importance level\\n', 'of the first scale (bad–good ), we can retrain the model with\\n', 'features based on the nine other scales and compare the85\\n', '\\n', '\\x0ctable 2: ranks of predictive feature sets for regular word2vec models (w2v) and osgood score models\\n', '(osg) in the immediate post-test data. all models are significantly better than the baseline model. (bold:\\n', 'the selected model with highest overall rank.)\\n', 'features\\n', 'baseline\\n', 'rt\\n', 'dist\\n', 'resp\\n', 'chull\\n', 'dist+resp\\n', 'dist+chull\\n', '\\n', 'auc\\n', '0.68 [0.67, 0.69] (5)\\n', '0.69 [0.68, 0.70] (4)\\n', '0.72 [0.71, 0.74] (1)\\n', '0.70 [0.69, 0.71] (3)\\n', 'na\\n', '0.72 [0.71, 0.73] (2)\\n', 'na\\n', '\\n', 'w2v models\\n', 'f1\\n', '0.74 [0.73, 0.74] (5)\\n', '0.75 [0.75, 0.76] (3)\\n', '0.76 [0.75, 0.76] (2)\\n', '0.75 [0.74, 0.76] (4)\\n', 'na\\n', '0.76 [0.75, 0.77] (1)\\n', 'na\\n', '\\n', 'err\\n', '0.33 [0.33, 0.34] (5)\\n', '0.31 [0.31, 0.32] (4)\\n', '0.29 [0.28, 0.30] (2)\\n', '0.31 [0.30, 0.32] (3)\\n', 'na\\n', '0.29 [0.28, 0.30] (1)\\n', 'na\\n', '\\n', 'auc\\n', '0.68 [0.67, 0.69] (5)\\n', '0.69 [0.68, 0.70] (2)\\n', '0.67 [0.66, 0.68] (7)\\n', '0.69 [0.68, 0.70] (1)\\n', '0.69 [0.68, 0.70] (3)\\n', '0.68 [0.67, 0.69] (4)\\n', '0.67 [0.66, 0.68] (6)\\n', '\\n', 'osg models\\n', 'f1\\n', '0.74 [0.73, 0.74] (5)\\n', '0.75 [0.74, 0.76] (2)\\n', '0.73 [0.73, 0.74] (7)\\n', '0.75 [0.75, 0.76] (1)\\n', '0.74 [0.73, 0.75] (4)\\n', '0.74 [0.73, 0.75] (3)\\n', '0.74 [0.73, 0.74] (6)\\n', '\\n', 'err\\n', '0.33 [0.33, 0.34] (7)\\n', '0.31 [0.31, 0.32] (2)\\n', '0.33 [0.32, 0.34] (6)\\n', '0.31 [0.30, 0.32] (1)\\n', '0.32 [0.31, 0.33] (4)\\n', '0.31 [0.31, 0.32] (3)\\n', '0.33 [0.32, 0.34] (5)\\n', '\\n', 'table 3: ranks of predictive feature sets for w2v and osg models in the delayed post-test data. all models\\n', 'are significantly better than the baseline model. (bold: the selected model with highest overall rank.)\\n', 'features\\n', 'baseline\\n', 'rt\\n', 'dist\\n', 'resp\\n', 'chull\\n', 'dist+resp\\n', 'dist+chull\\n', '\\n', 'auc\\n', '0.65 [0.64, 0.67] (5)\\n', '0.67 [0.65, 0.68] (3)\\n', '0.66 [0.64, 0.68] (4)\\n', '0.69 [0.67, 0.71] (1)\\n', 'na\\n', '0.68 [0.66, 0.70] (2)\\n', 'na\\n', '\\n', 'w2v models\\n', 'f1\\n', '0.75 [0.74, 0.76] (5)\\n', '0.76 [0.76, 0.77] (4)\\n', '0.77 [0.76, 0.78] (3)\\n', '0.77 [0.76, 0.78] (2)\\n', 'na\\n', '0.78 [0.77, 0.79] (1)\\n', 'na\\n', '\\n', 'err\\n', '0.33 [0.32, 0.34] (5)\\n', '0.31 [0.30, 0.32] (3)\\n', '0.31 [0.30, 0.32] (4)\\n', '0.30 [0.29, 0.31] (2)\\n', 'na\\n', '0.30 [0.29, 0.31] (1)\\n', 'na\\n', '\\n', 'performance of the newly trained model with the existing\\n', 'full-scale model.\\n', 'in table 4, we picked the top five scales that were\\n', 'important in individual prediction tasks. we found that bigsmall, helpful-harmful, complex-simple, and fast-slow were\\n', 'commonly important osgood scales for predicting students’\\n', 'performance in immediate post-test and delayed post-test\\n', 'sessions. scales like bad-good and passive-active were only\\n', 'important scales in the immediate post-test prediction.\\n', 'likewise, new-old was an important scale only in the delayed\\n', 'post-test prediction.\\n', 'table 4: scale-wise importance of each osgood\\n', 'scale. scales were selected based on the sum of each\\n', 'evaluation metric’s rank. (bold: osgood scales that\\n', 'were commonly important in both prediction tasks;\\n', '*: top five scales in each prediction task including\\n', 'tied ranks)\\n', 'scales\\n', 'bad-good\\n', 'passive-active\\n', 'powerful-helpless\\n', 'big-small\\n', 'helpful-harmful\\n', 'complex-simple\\n', 'fast-slow\\n', 'noisy-quiet\\n', 'new-old\\n', 'healthy-sick\\n', '\\n', '4.2.2\\n', '\\n', 'imm. post-test\\n', 'auc f1 err all\\n', '1\\n', '1\\n', '1\\n', '1*\\n', '2\\n', '4\\n', '3\\n', '2*\\n', '7\\n', '9\\n', '6\\n', '7.5\\n', '3\\n', '3\\n', '4\\n', '3*\\n', '4\\n', '6\\n', '5\\n', '5.5*\\n', '8\\n', '5\\n', '2\\n', '5.5*\\n', '5\\n']\n"
     ]
    }
   ],
   "source": [
    "# 3) print the first 1000 characters of the first document to see what it \n",
    "# looks like (we'll use this as a sanity check below)\n",
    "\n",
    "print(documents[0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['semantic score-based features\\n', '\\n', 'we now describe the semantic features tested in our\\n', 'prediction models.\\n', '\\n', '3.2.1\\n', '\\n', 'semantic scales\\n', '\\n', 'for this study, we used semantic scales from osgood’s study\\n', '[16]. ten scales were selected by a cognitive psychologist as\\n', 'being considered semantic attributes that can be detected\\n', 'during word learning (figure 2). each semantic scale\\n', 'consists of pairs of semantic attributes. for example, the\\n', 'bad–good scale can show how the meaning of a word can\\n', 'be projected on a scale with bad and good located at either\\n', '\\n', 'basic semantic distance scores\\n', '\\n', 'to extract meaningful semantic information, we have\\n', 'applied the following measures that can be used to explain\\n', 'various characteristics of student responses for different\\n', 'target words. in this study, we used a pre-trained model\\n', 'for word2vec,1 built based on the google news corpus\\n', '(100 billion tokens with 3 million unique vocabularies,\\n', 'using a negative sampling algorithm), to measure semantic\\n', 'similarity between words. the output of the pre-trained\\n', 'word2vec model contained a numeric vector with 300\\n', 'hundred dimensions.\\n', 'first, we calculated the relationship between word pairs (i.e.,\\n', 'a single student response and the target word, or a pair of\\n', 'responses) in both the regular word2vec (w2v) score and\\n', 'the osgood semantic scale (osg) score. in the w2v score,\\n', 'the semantic relationship between words was represented\\n', 'with a cosine similarity between word vectors:\\n', 'dw2v (w1 , w2 ) = 1 − |sim(v (w1 ), v (w2 ))|.\\n', '\\n', '(1)\\n', '\\n', 'in this equation, the function v returned the vectorized\\n', 'representation of the word (w1 or w2 ) from the pre-trained\\n', 'word2vec model. by calculating the cosine similarity\\n', 'between two vectors (a cosine similarity function is noted\\n', 'as sim), we could extract a single numeric similarity score\\n', 'between two words. this score was converted into a\\n', 'distance-like score by taking the absolute value of the cosine\\n', 'similarity score and subtracting from one.\\n', 'for the osg score, we extracted two different types of\\n', 'scores: a non-normalized score and a normalized score. a\\n', 'non-normalized score showed how a word is similar to a\\n', 'single anchor word (e.g., bad or good ) from the osgood scale.\\n', 'non\\n', 'sosg\\n', '(w, ai,j ) = sim(v (w), v (ai,j ))\\n', '\\n', '(2)\\n', '\\n', 'non\\n', 'non\\n', 'non\\n', 'dosg\\n', '(w1 , w2 ; ai,j ) = |sosg\\n', '(w1 , ai,j )| − |sosg\\n', '(w2 , ai,j )| (3)\\n', '\\n', 'in equation 2, ai,j represents a single anchor word (j) in\\n', 'the i-th osgood scale. the similarity between the anchor\\n', 'word and the evaluating word w was calculated with cosine\\n', 'similarity of word2vec outcomes for both words. in a nonnormalized setting, the distance between two words given\\n', 'by a particular anchor word was calculated by the difference\\n', 'of absolute cosine similarity scores (equation 3).\\n', 'the second type of osg score is a normalized score. by\\n', 'using word2vec’s ability to do arithmetical calculation of\\n', '1\\n', 'api and pre-trained model for word2vec was downloaded\\n', 'from this url: https://github.com/3top/word2vec-api83\\n', '\\n', '\\x0cmultiple word vectors, the normalized osg score provided\\n', 'a relative location of the word from two anchor ends of the\\n', 'osgood scale.\\n', 'nrm\\n', 'sosg\\n', '(w, ai ) = sim(v (w), v (ai,1 ) − v (ai,2 ))\\n', 'nrm\\n', 'nrm\\n', 'nrm\\n', 'dosg\\n', '(w1 , w2 ; ai ) = |sosg\\n', '(w1 , ai ) − sosg\\n', '(w2 , ai )|\\n', '\\n', '(4)\\n', '(5)\\n', '\\n', 'in equation 4, the output represents the cosine similarity\\n', 'score between the word w and two anchor words (ai,1\\n', 'and ai,2 ). for example, if the cosine similarity score of\\n', 'nrm\\n', 'sosg\\n', '(w, ai ) is close to -1, it means the word w is close to\\n', 'the first anchor word ai,1 . if the score is close to 1, it is vice\\n', 'versa. in equation 5, the distance between two words was\\n', 'calculated as the absolute value of the difference between\\n', 'two cosine similarity measures.\\n', '\\n', '3.2.3\\n', '\\n', 'deriving predictive features\\n', '\\n', 'based on semantic distance equations explained in the\\n', 'previous section, this section explains examples of predictive\\n', 'features that we used to predict students’ short-term\\n', 'learning and long-term retention.\\n', 'distance between the target word and the\\n', 'response. for regular word2vec score models and osgood\\n', 'scale score models, distance measures between the target\\n', 'word and the response (by using equations 1 and 5) were\\n', 'used to estimate the accuracy of the response to a question.\\n', 'this feature represents the trial-by-trial answer accuracy of\\n', 'a student response. each response sequence for the target\\n', 'word contained four distance scores.\\n', 'difference between responses. another feature that\\n', 'we used in both types of models was the difference between\\n', 'responses. this feature could capture how a student’s\\n', 'current answer is semantically different from the previous\\n', 'response. from each response sequence, we could extract\\n', 'three derivative scores from four responses.\\n', 'convex hull area of responses.\\n', 'alternative to\\n', 'the difference between responses feature, osgood scale\\n', 'models were also tested with the area size of convex hull\\n', 'that can be generated by responses calculated with nonnormalized osgood scale scores (equation 3). for example,\\n', 'for each osgood scale, a non-normalized score provided\\n', 'two-dimensional scores that can be used for geometric\\n', 'representation. by putting the target word in an origin\\n', 'position, a sequence of responses can create a polygon\\n', 'that can represent the semantic area that the student\\n', 'explored with responses. since some response sequences\\n', 'were unable to generate the polygon by including less than\\n', 'three unique responses, we added a small, random noise\\n', 'that uniformly distributed (between −10−4 and 10−4 ) to all\\n', 'response points. additionally, a value of 10−20 was added to\\n', 'all convex hull area output to create a visible lower-bound\\n', 'value.\\n', 'unlike the measure of difference between responses, this\\n', 'feature also considers angles that can be created between\\n', 'responses and the target word. this representation can\\n', 'provide more information than just using difference between\\n', 'responses.\\n', '\\n', '3.3\\n', '\\n', 'modeling\\n', '\\n', 'to predict students’ short-term learning and long-term\\n', 'retention, we used a mixed-effect logistic regression model\\n', '\\n', '(mlr). mlr is a general form of logistic regression model\\n', 'that includes random effect factors to capture variations\\n', 'from repeated measures.\\n', '\\n', '3.3.1\\n', '\\n', 'off-line variables\\n', '\\n', 'off-line variables capture item- or subject-level variances\\n', 'that can be observed repeatedly from the data. in this study,\\n', 'we used multiple off-line variables as random effect factors.\\n', 'first, results from familiarity-rating and synonym-selection\\n', 'questions from the pre-test session were used to include\\n', 'item- and subject-level variances. both variables include\\n', 'information on the student’s prior domain knowledge level\\n', 'for target words. second, the question difficulty condition\\n', 'was considered as an item group level factor. in the analysis,\\n', 'sentences for the target word that were presented to the\\n', 'student contained the same difficulty level, either high or\\n', 'medium contextual constraint levels, over four trials. third,\\n', 'a different experiment group was used as a subject group\\n', 'factor. as described in section 3.1.1, this study contains\\n', 'data from students in different institutions in separate\\n', 'geographic locations. the inclusion of these participant\\n', 'groups in the model can be used to explain different\\n', 'short-term learning outcomes and long-term retention by\\n', 'demographic groups.\\n', '\\n', '3.3.2\\n', '\\n', 'model building\\n', '\\n', 'in this study, we compared the performance of mlr models\\n', 'with four different feature types. first, the baseline model\\n', 'was set to indicate the mlr model’s performance without\\n', 'any fixed effect variables but only with random intercepts.\\n', 'second, the response time model was built to be compared\\n', 'with semantic score-based models. many previous studies\\n', 'have used response time as an important predictor of student\\n', 'engagement and learning [2, 12]. in this study, we used two\\n', 'types of response time variables, the latency for initiating\\n', 'the response and finishing typing the response, as predictive\\n', 'features. both variables were measured in milliseconds over\\n', 'four trials and natural log transformed for the analysis.\\n', 'third, semantic features from regular word2vec scores were\\n', 'used as predictors. this model was built to show how\\n', 'semantic scores from word2vec can be useful for predicting\\n', 'students’ short- and long-term performance in dscovar.\\n', 'lastly, osgood scale-based features were used as predictors.\\n', 'this model was compared with the regular word2vec score\\n', 'model to examine the effectiveness of using osgood scales for\\n', 'evaluating students’ performance in dscovar. for these\\n', 'semantic-score based models, we tested out different types\\n', 'of predictive features that were described in section 3.2.3.\\n', 'all models shared the same random intercept structure\\n', 'that treated each off-line variable as an individual random\\n', 'intercept.\\n', 'for osgood scale models, we also derived reduced-scale\\n', 'models. reduced-scale models were compared with the fullscale model, which uses all ten osgood scales. in this case,\\n', 'using fewer osgood scales can provide easier interpretation\\n', 'of semantic analysis for intelligent tutoring system users.\\n', '\\n', '3.3.3\\n', '\\n', 'model evaluation\\n', '\\n', 'to compare performance between different models, this\\n', 'study used various evaluation metrics, including auc (an\\n', 'area under the curve score from a response operating\\n', 'characteristic (roc) curve), f1 (a harmonic mean of\\n', 'precision and recall), and error rate (a ratio of the number of84\\n', '\\n', '\\x0cmisclassified items over total items). 95% confidence interval\\n', 'of each evaluation metric was calculated from the outcome of\\n', 'a ten-fold cross-validation process repeated over ten times.\\n', 'to select the semantic score-based features for models based\\n', 'on regular word2vec scores and osgood scale scores, we\\n', 'used rankings from each evaluation metric. the model with\\n', 'the highest overall rank (i.e., sum the ranks from auc, f1 ,\\n', 'and error rate, and select the model with the lowest ranksum value) was considered the best-performing model for\\n', 'the score type (i.e., models based on the regular word2vec\\n', 'score or osgood scale score). more details on this process\\n', 'will be illustrated in the next section.\\n', '\\n', '4. results\\n', '4.1 selecting models\\n', '\\n', 'in this section, we selected the best-performing model based\\n', 'on the models’ overall ranks in each evaluation metric. all\\n', 'model parameters were trained in each fold of repeated\\n', 'cross-validation. we calculated 95% confidence intervals for\\n', 'comparison. to calculate the confidence interval of f1 and\\n', 'error rate measures, the maximum (f1 ) and minimum (error\\n', 'rate) scores of each fold were extracted. these maximum\\n', 'and minimum values were derived from applying multiple\\n', 'cutoff points to the mixed-effect regression model.\\n', '\\n', '4.1.1\\n', '\\n', 'predicting immediate learning\\n', '\\n', 'first, we built models that predict the students’ immediate\\n', 'learning from the immediate post-test session.\\n', 'from\\n', 'models based on regular word2vec scores (w2v), the model\\n', 'with the distance between the target and responses and\\n', 'the difference between responses (dist+resp) provided the\\n', 'highest rank from various evaluation metrics (table 2).\\n', 'from models based on osgood scales (osg), the model with\\n', 'the difference between responses (resp) provided the highest\\n', 'rank.\\n', 'the selected w2v model provided significantly better\\n', 'performance than the baseline model. the selected osg\\n', 'model also showed significantly better performance than the\\n', 'baseline model, except for the auc score. the selected\\n', 'w2v model was significantly better than the model using\\n', 'response time features in the auc score and error rates.\\n', 'the selected w2v model showed significantly better\\n', 'performance than the osg model only with the auc score.\\n', 'figure 3 shows that the w2v model has a slightly larger area\\n', 'under the roc curve than the osg model. in the precision\\n', 'and recall curve, the selected w2v model provides more\\n', 'balanced trade-offs between precision and recall measures.\\n', 'the selected osg model outperforms the w2v model in\\n', 'precision only in a very low recall measure range.\\n', '\\n', '4.1.2\\n', '\\n', 'predicting long-term retention\\n', '\\n', 'we also built prediction models to predict the students’\\n', 'long-term retention in the delayed post-test session. in\\n', 'this analysis, a student response was included only when\\n', 'the student provided correct answers to the immediate\\n', 'post-test session questions.\\n', 'among w2v score-based\\n', 'models, the best-performing model contained the same\\n', 'feature types as the immediate post-test results (table 3).\\n', 'by using the distance between the target and responses\\n', 'and difference between responses (dist+resp), the model\\n', '\\n', 'achieved significantly better performance than the baseline\\n', 'model, except for the auc score.\\n', 'for osg models, the model with a convex hull area of\\n', 'responses (chull ) provided the highest overall rank from\\n', 'evaluation metrics (table 3). the results were significantly\\n', 'better than the baseline model, and marginally better than\\n', 'the w2v model. both selected w2v and osg models were\\n', 'marginally better than the response time model, except the\\n', 'error rate of the osg model was significantly better.\\n', 'in figure 3, the selected w2v model slightly outperforms\\n', 'the osg model in mid-range true positive rates, while\\n', 'the osg model performed slightly better in a higher true\\n', 'positive area. precision and recall curves show similar\\n', 'patterns to those we observed from the immediate post-test\\n', 'prediction models. the osg model only outperforms the\\n', 'w2v model in a very low recall value area.\\n', '\\n', '4.1.3 comparing models\\n', 'compared to the selected w2v model in the immediate\\n', 'post-test condition, the selected w2v model in the delayed\\n', 'post-test retention condition showed a significantly lower\\n', 'auc score, marginally higher f1 score, and marginally\\n', 'higher error rate. in terms of osg models, the selected osg\\n', 'model for delayed post-test retention showed a significantly\\n', 'better f1 score and error rates than the selected osg model\\n', 'in the immediate post-test condition. based on these results,\\n', 'we can argue that osgood scale scores can be more useful for\\n', 'predicting student retention in the delayed post-test session\\n', 'than predicting the outcome from the immediate post-test.\\n', 'in terms of selected feature types, the best-performing\\n', 'osg models used features based on the difference between\\n', 'responses (resp) or the convex hull area (chull ) that was\\n', 'created from the relative location of the responses. on the\\n', 'other hand, selected w2v models used both the distance\\n', 'between the target word and responses and difference\\n', 'between responses (dist+resp).\\n', 'when we compared\\n', 'both w2v and osg models using the difference between\\n', 'responses feature, we found that performance is similar in\\n', 'the immediate post-test data. however, the osg model\\n', 'was significantly better in the delayed post-test data. these\\n', 'results show that osgood scale scores can be more useful for\\n', 'representing the relationship among response sequences.\\n', '\\n', '4.2 comparing the osgood scales\\n', '\\n', 'to identify which osgood scales are more helpful than\\n', 'others for predicting students’ performance, we conducted\\n', 'a scale-wise importance analysis. the results from this\\n', 'section reveal which osgood scales are more important than\\n', 'others, and how the performance of prediction models with\\n', 'a reduced number of scales is comparable with the full-scale\\n', 'model.\\n', '\\n', '4.2.1\\n', '\\n', 'identifying more important osgood scales\\n', '\\n', 'in this section, based on the selected osgood score model\\n', 'from section 4.1, we identified the level of contribution for\\n', 'features based on each osgood scale. for example, the\\n', 'selected osg model for predicting the immediate post-test\\n', 'data uses the difference between responses in ten osgood\\n', 'scales as features. in order to diagnose the importance level\\n', 'of the first scale (bad–good ), we can retrain the model with\\n', 'features based on the nine other scales and compare the85\\n', '\\n', '\\x0ctable 2: ranks of predictive feature sets for regular word2vec models (w2v) and osgood score models\\n', '(osg) in the immediate post-test data. all models are significantly better than the baseline model. (bold:\\n', 'the selected model with highest overall rank.)\\n', 'features\\n', 'baseline\\n', 'rt\\n', 'dist\\n', 'resp\\n', 'chull\\n', 'dist+resp\\n', 'dist+chull\\n', '\\n', 'auc\\n', '0.68 [0.67, 0.69] (5)\\n', '0.69 [0.68, 0.70] (4)\\n', '0.72 [0.71, 0.74] (1)\\n', '0.70 [0.69, 0.71] (3)\\n', 'na\\n', '0.72 [0.71, 0.73] (2)\\n', 'na\\n', '\\n', 'w2v models\\n', 'f1\\n', '0.74 [0.73, 0.74] (5)\\n', '0.75 [0.75, 0.76] (3)\\n', '0.76 [0.75, 0.76] (2)\\n', '0.75 [0.74, 0.76] (4)\\n', 'na\\n', '0.76 [0.75, 0.77] (1)\\n', 'na\\n', '\\n', 'err\\n', '0.33 [0.33, 0.34] (5)\\n', '0.31 [0.31, 0.32] (4)\\n', '0.29 [0.28, 0.30] (2)\\n', '0.31 [0.30, 0.32] (3)\\n', 'na\\n', '0.29 [0.28, 0.30] (1)\\n', 'na\\n', '\\n', 'auc\\n', '0.68 [0.67, 0.69] (5)\\n', '0.69 [0.68, 0.70] (2)\\n', '0.67 [0.66, 0.68] (7)\\n', '0.69 [0.68, 0.70] (1)\\n', '0.69 [0.68, 0.70] (3)\\n', '0.68 [0.67, 0.69] (4)\\n', '0.67 [0.66, 0.68] (6)\\n', '\\n', 'osg models\\n', 'f1\\n', '0.74 [0.73, 0.74] (5)\\n', '0.75 [0.74, 0.76] (2)\\n', '0.73 [0.73, 0.74] (7)\\n', '0.75 [0.75, 0.76] (1)\\n', '0.74 [0.73, 0.75] (4)\\n', '0.74 [0.73, 0.75] (3)\\n', '0.74 [0.73, 0.74] (6)\\n', '\\n', 'err\\n', '0.33 [0.33, 0.34] (7)\\n', '0.31 [0.31, 0.32] (2)\\n', '0.33 [0.32, 0.34] (6)\\n', '0.31 [0.30, 0.32] (1)\\n', '0.32 [0.31, 0.33] (4)\\n', '0.31 [0.31, 0.32] (3)\\n', '0.33 [0.32, 0.34] (5)\\n', '\\n', 'table 3: ranks of predictive feature sets for w2v and osg models in the delayed post-test data. all models\\n', 'are significantly better than the baseline model. (bold: the selected model with highest overall rank.)\\n', 'features\\n', 'baseline\\n', 'rt\\n', 'dist\\n', 'resp\\n', 'chull\\n', 'dist+resp\\n', 'dist+chull\\n', '\\n', 'auc\\n', '0.65 [0.64, 0.67] (5)\\n', '0.67 [0.65, 0.68] (3)\\n', '0.66 [0.64, 0.68] (4)\\n', '0.69 [0.67, 0.71] (1)\\n', 'na\\n', '0.68 [0.66, 0.70] (2)\\n', 'na\\n', '\\n', 'w2v models\\n', 'f1\\n', '0.75 [0.74, 0.76] (5)\\n', '0.76 [0.76, 0.77] (4)\\n', '0.77 [0.76, 0.78] (3)\\n', '0.77 [0.76, 0.78] (2)\\n', 'na\\n', '0.78 [0.77, 0.79] (1)\\n', 'na\\n', '\\n', 'err\\n', '0.33 [0.32, 0.34] (5)\\n', '0.31 [0.30, 0.32] (3)\\n', '0.31 [0.30, 0.32] (4)\\n', '0.30 [0.29, 0.31] (2)\\n', 'na\\n', '0.30 [0.29, 0.31] (1)\\n', 'na\\n', '\\n', 'performance of the newly trained model with the existing\\n', 'full-scale model.\\n', 'in table 4, we picked the top five scales that were\\n', 'important in individual prediction tasks. we found that bigsmall, helpful-harmful, complex-simple, and fast-slow were\\n', 'commonly important osgood scales for predicting students’\\n', 'performance in immediate post-test and delayed post-test\\n', 'sessions. scales like bad-good and passive-active were only\\n', 'important scales in the immediate post-test prediction.\\n', 'likewise, new-old was an important scale only in the delayed\\n', 'post-test prediction.\\n', 'table 4: scale-wise importance of each osgood\\n', 'scale. scales were selected based on the sum of each\\n', 'evaluation metric’s rank. (bold: osgood scales that\\n', 'were commonly important in both prediction tasks;\\n', '*: top five scales in each prediction task including\\n', 'tied ranks)\\n', 'scales\\n', 'bad-good\\n', 'passive-active\\n', 'powerful-helpless\\n', 'big-small\\n', 'helpful-harmful\\n', 'complex-simple\\n', 'fast-slow\\n', 'noisy-quiet\\n', 'new-old\\n', 'healthy-sick\\n', '\\n', '4.2.2\\n', '\\n', 'imm. post-test\\n', 'auc f1 err all\\n', '1\\n', '1\\n', '1\\n', '1*\\n', '2\\n', '4\\n', '3\\n', '2*\\n', '7\\n', '9\\n', '6\\n', '7.5\\n', '3\\n', '3\\n', '4\\n', '3*\\n', '4\\n', '6\\n', '5\\n', '5.5*\\n', '8\\n', '5\\n', '2\\n', '5.5*\\n', '5\\n', '2\\n', '7\\n', '4*\\n', '6\\n', '8\\n', '8\\n', '7.5\\n', '9\\n', '7\\n', '9\\n', '9\\n', '10\\n', '10 10\\n', '10\\n', '\\n', 'del. post-test\\n', 'auc f1 err all\\n', '4\\n', '10 4\\n', '6\\n', '8\\n', '6\\n', '6\\n', '7\\n', '10\\n', '8\\n', '10\\n', '10\\n', '1\\n', '3\\n', '2\\n', '2*\\n', '2\\n', '1\\n', '1\\n', '1*\\n', '3\\n', '5\\n', '7\\n', '4.5*\\n', '6\\n', '4\\n', '3\\n', '3*\\n', '7\\n', '9\\n', '9\\n', '9\\n', '5\\n', '2\\n', '8\\n', '4.5*\\n', '9\\n', '7\\n', '5\\n', '8\\n', '\\n', 'performance of reduced models\\n', '\\n', 'based on the scale-wise importance analysis results, we built\\n', 'reduced-scale models that only contain features with more\\n', 'important osgood scales. the prediction performance of\\n', 'reduced-scale models was similar or marginally better than\\n', 'full-scale osg models. for example, the osg model for\\n', 'predicting the immediate post-test outcome with the top\\n', 'two scales (bad–good and passive–active) were marginally\\n', 'better than the full-scale model (auc: 0.71 [0.70, 0.72], f1 :\\n', '0.76 [0.75, 0.77], error rate: 0.30 [0.29, 0.30]). similar results\\n', 'were observed for predicting retention in the delayed posttest (selected scales: helpful–harmful, big–small ) (auc: 0.71\\n', '[0.69, 0.72], f1 : 0.79 [0.78, 0.80], error rate: 0.28 [0.27,\\n', '\\n', 'auc\\n', '0.65 [0.64, 0.67] (5)\\n', '0.67 [0.65, 0.68] (3)\\n', '0.66 [0.64, 0.68] (4)\\n', '0.63 [0.61, 0.65] (7)\\n', '0.69 [0.68, 0.71] (1)\\n', '0.64 [0.62, 0.66] (6)\\n', '0.69 [0.67, 0.71] (2)\\n', '\\n', 'osg models\\n', 'f1\\n', '0.75 [0.74, 0.76] (7)\\n', '0.76 [0.76, 0.77] (5)\\n', '0.78 [0.77, 0.79] (3)\\n', '0.76 [0.75, 0.77] (6)\\n', '0.78 [0.77, 0.79] (2)\\n', '0.77 [0.76, 0.78] (4)\\n', '0.78 [0.78, 0.79] (1)\\n', '\\n', 'err\\n', '0.33 [0.32, 0.34] (7)\\n', '0.31 [0.30, 0.32] (5)\\n', '0.30 [0.29, 0.31] (3)\\n', '0.32 [0.31, 0.33] (6)\\n', '0.28 [0.27, 0.29] (1)\\n', '0.31 [0.29, 0.32] (4)\\n', '0.29 [0.27, 0.30] (2)\\n', '\\n', '0.29]). although differences were small, the results indicate\\n', 'that using a small number of osgood scales can be similarly\\n', 'effective to the full-scale model.\\n', '\\n', '5.\\n', '\\n', 'discussion and conclusions\\n', '\\n', 'in this paper, we introduced a novel semantic similarity\\n', 'scoring method that uses predefined semantic scales to\\n', 'represent the relationship between words. by combining\\n', 'osgood’s semantic scales [16] and word2vec [13], we could\\n', 'automatically extract the semantic relationship between\\n', 'two words in a more interpretable manner. to show this\\n', 'method can effectively represent students’ knowledge in\\n', 'vocabulary acquisition, we built prediction models that can\\n', 'be used to predict the student’s immediate learning and\\n', 'long-term retention. we found that our models performed\\n', 'significantly better than the baseline and the responsetime-based models. in the future, we believe results from\\n', 'using an osgood scale-based student model could be used\\n', 'to provide a more personalized learning experience, such\\n', 'as generating questions that can improve an individual\\n', 'student’s understanding for specific semantic attributes.\\n', 'based on our findings, we have identified the following\\n', 'points for further discussion. first, in section 4.1, we\\n', 'found that models using osgood scale scores perform\\n', 'similarly with models using regular word2vec scores\\n', 'for predicting students’ long-term retention of acquired\\n', 'vocabulary. however, we think our models can be further\\n', 'improved by incorporating additional features. for example,\\n', 'non-semantic score-based features like response time and\\n', 'orthographic similarity among responses can be useful\\n', 'features for capturing different patterns of false predictions\\n', 'of current models. moreover, some general measures to\\n', 'capture a student’s meta-cognitive or linguistic skills could\\n', 'be helpful to explain different retention results found even if\\n', 'students provided the same response sequences. similarly, in\\n', 'section 4.1.3, we found that osgood scores can be a better\\n', 'metric to characterize the relationship between responses\\n', 'in terms of predicting students’ retention. a composite\\n', 'model that uses both regular word2vec score-based feature\\n', '(target-response distance) and osgood scale score-based\\n', 'feature (response-response distance) may also provide better86\\n', '\\n', '\\x0cfigure 3: roc curves and precision and recall curves for selected immediate post-test prediction models\\n', '(left) and delayed post-test prediction models (right). curves are smoothed out with a local polynomial\\n', 'regression method based on repeated cross-validation results.\\n', '\\n', 'prediction performance.\\n', 'second, we found that models with a reduced number of\\n', 'osgood scales performed marginally better than the fullscale model. however, differences were very small. since\\n', 'this study only used some of the semantic scales from\\n', 'osgood’s study [16], further investigation would be required\\n', 'to examine the validity of these scales, including other scales\\n', 'not used for this study, for capturing the semantic attributes\\n', 'of student responses during vocabulary learning.\\n', 'also, there were some limitations in the current study\\n', 'and areas for future work. first, expanding the scope\\n', 'of analysis to the full set of experimental conditions\\n', 'used in the study may reveal more complex interactions\\n', 'between these conditions and students’ short- and longterm learning. second, this study used a fixed threshold\\n', 'of 0.5 for investigating false prediction results. however, an\\n', 'optimal threshold for each participant group or prediction\\n', 'model could be selected, especially if there are different false\\n', 'positive or negative patterns observed for different groups\\n', 'of students. lastly, this study collected data from a single\\n', 'vocabulary tutoring system that was used in a classroom\\n', 'setting. applying the proposed method to data that was\\n', 'collected from a non-classroom setting or other vocabulary\\n', 'learning system would be useful to show the generalization\\n', 'of our suggested method.\\n', '\\n', '6.\\n', '\\n', 'acknowledgments\\n', '\\n', 'the research reported here was supported by the institute of\\n', 'education sciences, u.s. department of education, through\\n', 'grant r305a140647 to the university of michigan. the\\n', 'opinions expressed are those of the authors and do not\\n', 'represent views of the institute or the u.s. department\\n', 'of education. we thank dr. charles perfetti and his lab\\n', 'team at the university of pittsburgh, particularly adeetee\\n', 'bhide and kim muth, and the helpful personnel at all of our\\n', 'partner schools.\\n', '\\n', '7.\\n', '\\n', 'references\\n', '\\n', '[1] s. adlof, g. frishkoff, j. dandy, and c. perfetti. effects of\\n', 'induced orthographic and semantic knowledge on\\n', 'subsequent learning: a test of the partial knowledge\\n', 'hypothesis. reading and writing, 29(3):475–500, 2016.\\n', '[2] j. e. beck. engagement tracing: using response times to\\n', 'model student disengagement. artificial intelligence in\\n', 'education: supporting learning through intelligent and\\n', 'socially informed technology, 125:88, 2005.\\n', '[3] k. collins-thompson and j. callan. automatic and human\\n', 'scoring of word definition responses. in hlt-naacl,\\n', 'pages 476–483, 2007.\\n', '[4] m. coltheart. the mrc psycholinguistic database. the\\n', '\\n', '[5]\\n', '[6]\\n', '[7]\\n', '\\n', '[8]\\n', '\\n', '[9]\\n', '\\n', '[10]\\n', '[11]\\n', '\\n', '[12]\\n', '[13]\\n', '\\n', '[14]\\n', '[15]\\n', '[16]\\n', '[17]\\n', '\\n', '[18]\\n', '[19]\\n', '\\n', '[20]\\n', '\\n', 'quarterly journal of experimental psychology,\\n', '33(4):497–505, 1981.\\n', 'e. dale. vocabulary measurement: techniques and major\\n', 'findings. elementary english, 42(8):895–948, 1965.\\n', 'f. t. durso and w. j. shore. partial knowledge of word\\n', 'meanings. journal of experimental psychology: general,\\n', '120(2):190, 1991.\\n', 'g. a. frishkoff, k. collins-thompson, l. hodges, and\\n', 's. crossley. accuracy feedback improves word learning\\n', 'from context: evidence from a meaning-generation task.\\n', 'reading and writing, 29(4):609–632, 2016.\\n', 'g. a. frishkoff, k. collins-thompson, s. nam, l. hodges,\\n', 'and s. a. crossley. dynamic support of contextual\\n', 'vocabulary acquisition for reading (dscovar): an\\n', 'intelligent tutoring system for contextual word learning.\\n', 'handbook on educational technologies for literacy, 2016.\\n', 'g. a. frishkoff, c. a. perfetti, and k. collins-thompson.\\n', 'predicting robust vocabulary growth from measures of\\n', 'incremental learning. scientific studies of reading,\\n', '15(1):71–91, 2011.\\n', 't. k. landauer. latent semantic analysis. wiley online\\n', 'library, 2006.\\n', 'y. li, l. xu, f. tian, l. jiang, x. zhong, and e. chen.\\n', 'word embedding revisited: a new representation learning\\n', 'and explicit matrix factorization perspective. in\\n', 'proceedings of the 24th international joint conference on\\n', 'artificial intelligence, buenos aires, argentina, pages\\n', '3650–3656, 2015.\\n', 'y. ma, l. agnihotri, m. h. education, r. baker, and\\n', 's. mojarad. effect of student ability and question difficulty\\n', 'on duration. in educational data mining, 2016.\\n', 't. mikolov, i. sutskever, k. chen, g. s. corrado, and\\n', 'j. dean. distributed representations of words and phrases\\n', 'and their compositionality. in advances in neural\\n', 'information processing systems, pages 3111–3119, 2013.\\n', 'g. a. miller. wordnet: a lexical database for english.\\n', 'communications of the acm, 38(11):39–41, 1995.\\n', 's. nam. predicting off-task behaviors in an adaptive\\n', 'vocabulary learning system. in educational data mining,\\n', '2016.\\n', 'c. e. osgood, g. j. suci, and p. h. tannenbaum. the\\n', 'measurement of meaning. university of illinois press, 1957.\\n', 'k. ostrow, c. donnelly, s. adjei, and n. heffernan.\\n', 'improving student modeling through partial credit and\\n', 'problem difficulty. in proc. of the second acm conference\\n', 'on learning@scale, pages 11–20. acm, 2015.\\n', 'p. i. pavlik and j. r. anderson. practice and forgetting\\n', 'effects on vocabulary memory: an activation-based model\\n', 'of the spacing effect. cog. science, 29(4):559–586, 2005.\\n', 'e. g. van inwegen, s. a. adjei, y. wang, and n. t.\\n', 'heffernan. using partial credit and response history to\\n', 'model user knowledge. international educational data\\n', 'mining society, 2015.\\n', 'l. m. yonek. the effects of rich vocabulary instruction\\n', 'on students’ expository writing. phd thesis, university of\\n', 'pittsburgh, 2008.']\n"
     ]
    }
   ],
   "source": [
    "# 4) only select the text that's between the first occurence of the \n",
    "# the word \"abstract\" and the last occurence of the word \"reference\"\n",
    "# Optional: print the length of the string before and after, as a \n",
    "# sanity check\n",
    "# HINT: https://stackoverflow.com/questions/14496006/finding-last-occurrence-of-substring-in-string-replacing-that\n",
    "# read more about rfind: https://www.tutorialspoint.com/python/string_rfind.htm\n",
    "\n",
    "clean_documents = []\n",
    "\n",
    "for document in documents:\n",
    " a = (str(document).index(\"abstract\"))\n",
    " z = (str(document).rfind(\"reference\"))\n",
    " clean_documents.append(document[a:z])\n",
    " \n",
    "print(clean_documents[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['semantic score-based features ', ' ', 'we now describe the semantic features tested in our ', 'prediction models. ', ' ', '3.2.1 ', ' ', 'semantic scales ', ' ', 'for this study, we used semantic scales from osgood’s study ', '[16]. ten scales were selected by a cognitive psychologist as ', 'being considered semantic attributes that can be detected ', 'during word learning (figure 2). each semantic scale ', 'consists of pairs of semantic attributes. for example, the ', 'bad–good scale can show how the meaning of a word can ', 'be projected on a scale with bad and good located at either ', ' ', 'basic semantic distance scores ', ' ', 'to extract meaningful semantic information, we have ', 'applied the following measures that can be used to explain ', 'various characteristics of student responses for different ', 'target words. in this study, we used a pre-trained model ', 'for word2vec,1 built based on the google news corpus ', '(100 billion tokens with 3 million unique vocabularies, ', 'using a negative sampling algorithm), to measure semantic ', 'similarity between words. the output of the pre-trained ', 'word2vec model contained a numeric vector with 300 ', 'hundred dimensions. ', 'first, we calculated the relationship between word pairs (i.e., ', 'a single student response and the target word, or a pair of ', 'responses) in both the regular word2vec (w2v) score and ', 'the osgood semantic scale (osg) score. in the w2v score, ', 'the semantic relationship between words was represented ', 'with a cosine similarity between word vectors: ', 'dw2v (w1 , w2 ) = 1 − |sim(v (w1 ), v (w2 ))|. ', ' ', '(1) ', ' ', 'in this equation, the function v returned the vectorized ', 'representation of the word (w1 or w2 ) from the pre-trained ', 'word2vec model. by calculating the cosine similarity ', 'between two vectors (a cosine similarity function is noted ', 'as sim), we could extract a single numeric similarity score ', 'between two words. this score was converted into a ', 'distance-like score by taking the absolute value of the cosine ', 'similarity score and subtracting from one. ', 'for the osg score, we extracted two different types of ', 'scores: a non-normalized score and a normalized score. a ', 'non-normalized score showed how a word is similar to a ', 'single anchor word (e.g., bad or good ) from the osgood scale. ', 'non ', 'sosg ', '(w, ai,j ) = sim(v (w), v (ai,j )) ', ' ', '(2) ', ' ', 'non ', 'non ', 'non ', 'dosg ', '(w1 , w2 ; ai,j ) = |sosg ', '(w1 , ai,j )| − |sosg ', '(w2 , ai,j )| (3) ', ' ', 'in equation 2, ai,j represents a single anchor word (j) in ', 'the i-th osgood scale. the similarity between the anchor ', 'word and the evaluating word w was calculated with cosine ', 'similarity of word2vec outcomes for both words. in a nonnormalized setting, the distance between two words given ', 'by a particular anchor word was calculated by the difference ', 'of absolute cosine similarity scores (equation 3). ', 'the second type of osg score is a normalized score. by ', 'using word2vec’s ability to do arithmetical calculation of ', '1 ', 'api and pre-trained model for word2vec was downloaded ', 'from this url: https://github.com/3top/word2vec-api83 ', ' ', '\\\\x0cmultiple word vectors, the normalized osg score provided ', 'a relative location of the word from two anchor ends of the ', 'osgood scale. ', 'nrm ', 'sosg ', '(w, ai ) = sim(v (w), v (ai,1 ) − v (ai,2 )) ', 'nrm ', 'nrm ', 'nrm ', 'dosg ', '(w1 , w2 ; ai ) = |sosg ', '(w1 , ai ) − sosg ', '(w2 , ai )| ', ' ', '(4) ', '(5) ', ' ', 'in equation 4, the output represents the cosine similarity ', 'score between the word w and two anchor words (ai,1 ', 'and ai,2 ). for example, if the cosine similarity score of ', 'nrm ', 'sosg ', '(w, ai ) is close to -1, it means the word w is close to ', 'the first anchor word ai,1 . if the score is close to 1, it is vice ', 'versa. in equation 5, the distance between two words was ', 'calculated as the absolute value of the difference between ', 'two cosine similarity measures. ', ' ', '3.2.3 ', ' ', 'deriving predictive features ', ' ', 'based on semantic distance equations explained in the ', 'previous section, this section explains examples of predictive ', 'features that we used to predict students’ short-term ', 'learning and long-term retention. ', 'distance between the target word and the ', 'response. for regular word2vec score models and osgood ', 'scale score models, distance measures between the target ', 'word and the response (by using equations 1 and 5) were ', 'used to estimate the accuracy of the response to a question. ', 'this feature represents the trial-by-trial answer accuracy of ', 'a student response. each response sequence for the target ', 'word contained four distance scores. ', 'difference between responses. another feature that ', 'we used in both types of models was the difference between ', 'responses. this feature could capture how a student’s ', 'current answer is semantically different from the previous ', 'response. from each response sequence, we could extract ', 'three derivative scores from four responses. ', 'convex hull area of responses. ', 'alternative to ', 'the difference between responses feature, osgood scale ', 'models were also tested with the area size of convex hull ', 'that can be generated by responses calculated with nonnormalized osgood scale scores (equation 3). for example, ', 'for each osgood scale, a non-normalized score provided ', 'two-dimensional scores that can be used for geometric ', 'representation. by putting the target word in an origin ', 'position, a sequence of responses can create a polygon ', 'that can represent the semantic area that the student ', 'explored with responses. since some response sequences ', 'were unable to generate the polygon by including less than ', 'three unique responses, we added a small, random noise ', 'that uniformly distributed (between −10−4 and 10−4 ) to all ', 'response points. additionally, a value of 10−20 was added to ', 'all convex hull area output to create a visible lower-bound ', 'value. ', 'unlike the measure of difference between responses, this ', 'feature also considers angles that can be created between ', 'responses and the target word. this representation can ', 'provide more information than just using difference between ', 'responses. ', ' ', '3.3 ', ' ', 'modeling ', ' ', 'to predict students’ short-term learning and long-term ', 'retention, we used a mixed-effect logistic regression model ', ' ', '(mlr). mlr is a general form of logistic regression model ', 'that includes random effect factors to capture variations ', 'from repeated measures. ', ' ', '3.3.1 ', ' ', 'off-line variables ', ' ', 'off-line variables capture item- or subject-level variances ', 'that can be observed repeatedly from the data. in this study, ', 'we used multiple off-line variables as random effect factors. ', 'first, results from familiarity-rating and synonym-selection ', 'questions from the pre-test session were used to include ', 'item- and subject-level variances. both variables include ', 'information on the student’s prior domain knowledge level ', 'for target words. second, the question difficulty condition ', 'was considered as an item group level factor. in the analysis, ', 'sentences for the target word that were presented to the ', 'student contained the same difficulty level, either high or ', 'medium contextual constraint levels, over four trials. third, ', 'a different experiment group was used as a subject group ', 'factor. as described in section 3.1.1, this study contains ', 'data from students in different institutions in separate ', 'geographic locations. the inclusion of these participant ', 'groups in the model can be used to explain different ', 'short-term learning outcomes and long-term retention by ', 'demographic groups. ', ' ', '3.3.2 ', ' ', 'model building ', ' ', 'in this study, we compared the performance of mlr models ', 'with four different feature types. first, the baseline model ', 'was set to indicate the mlr model’s performance without ', 'any fixed effect variables but only with random intercepts. ', 'second, the response time model was built to be compared ', 'with semantic score-based models. many previous studies ', 'have used response time as an important predictor of student ', 'engagement and learning [2, 12]. in this study, we used two ', 'types of response time variables, the latency for initiating ', 'the response and finishing typing the response, as predictive ', 'features. both variables were measured in milliseconds over ', 'four trials and natural log transformed for the analysis. ', 'third, semantic features from regular word2vec scores were ', 'used as predictors. this model was built to show how ', 'semantic scores from word2vec can be useful for predicting ', 'students’ short- and long-term performance in dscovar. ', 'lastly, osgood scale-based features were used as predictors. ', 'this model was compared with the regular word2vec score ', 'model to examine the effectiveness of using osgood scales for ', 'evaluating students’ performance in dscovar. for these ', 'semantic-score based models, we tested out different types ', 'of predictive features that were described in section 3.2.3. ', 'all models shared the same random intercept structure ', 'that treated each off-line variable as an individual random ', 'intercept. ', 'for osgood scale models, we also derived reduced-scale ', 'models. reduced-scale models were compared with the fullscale model, which uses all ten osgood scales. in this case, ', 'using fewer osgood scales can provide easier interpretation ', 'of semantic analysis for intelligent tutoring system users. ', ' ', '3.3.3 ', ' ', 'model evaluation ', ' ', 'to compare performance between different models, this ', 'study used various evaluation metrics, including auc (an ', 'area under the curve score from a response operating ', 'characteristic (roc) curve), f1 (a harmonic mean of ', 'precision and recall), and error rate (a ratio of the number of84 ', ' ', '\\\\x0cmisclassified items over total items). 95% confidence interval ', 'of each evaluation metric was calculated from the outcome of ', 'a ten-fold cross-validation process repeated over ten times. ', 'to select the semantic score-based features for models based ', 'on regular word2vec scores and osgood scale scores, we ', 'used rankings from each evaluation metric. the model with ', 'the highest overall rank (i.e., sum the ranks from auc, f1 , ', 'and error rate, and select the model with the lowest ranksum value) was considered the best-performing model for ', 'the score type (i.e., models based on the regular word2vec ', 'score or osgood scale score). more details on this process ', 'will be illustrated in the next section. ', ' ', '4. results ', '4.1 selecting models ', ' ', 'in this section, we selected the best-performing model based ', 'on the models’ overall ranks in each evaluation metric. all ', 'model parameters were trained in each fold of repeated ', 'cross-validation. we calculated 95% confidence intervals for ', 'comparison. to calculate the confidence interval of f1 and ', 'error rate measures, the maximum (f1 ) and minimum (error ', 'rate) scores of each fold were extracted. these maximum ', 'and minimum values were derived from applying multiple ', 'cutoff points to the mixed-effect regression model. ', ' ', '4.1.1 ', ' ', 'predicting immediate learning ', ' ', 'first, we built models that predict the students’ immediate ', 'learning from the immediate post-test session. ', 'from ', 'models based on regular word2vec scores (w2v), the model ', 'with the distance between the target and responses and ', 'the difference between responses (dist+resp) provided the ', 'highest rank from various evaluation metrics (table 2). ', 'from models based on osgood scales (osg), the model with ', 'the difference between responses (resp) provided the highest ', 'rank. ', 'the selected w2v model provided significantly better ', 'performance than the baseline model. the selected osg ', 'model also showed significantly better performance than the ', 'baseline model, except for the auc score. the selected ', 'w2v model was significantly better than the model using ', 'response time features in the auc score and error rates. ', 'the selected w2v model showed significantly better ', 'performance than the osg model only with the auc score. ', 'figure 3 shows that the w2v model has a slightly larger area ', 'under the roc curve than the osg model. in the precision ', 'and recall curve, the selected w2v model provides more ', 'balanced trade-offs between precision and recall measures. ', 'the selected osg model outperforms the w2v model in ', 'precision only in a very low recall measure range. ', ' ', '4.1.2 ', ' ', 'predicting long-term retention ', ' ', 'we also built prediction models to predict the students’ ', 'long-term retention in the delayed post-test session. in ', 'this analysis, a student response was included only when ', 'the student provided correct answers to the immediate ', 'post-test session questions. ', 'among w2v score-based ', 'models, the best-performing model contained the same ', 'feature types as the immediate post-test results (table 3). ', 'by using the distance between the target and responses ', 'and difference between responses (dist+resp), the model ', ' ', 'achieved significantly better performance than the baseline ', 'model, except for the auc score. ', 'for osg models, the model with a convex hull area of ', 'responses (chull ) provided the highest overall rank from ', 'evaluation metrics (table 3). the results were significantly ', 'better than the baseline model, and marginally better than ', 'the w2v model. both selected w2v and osg models were ', 'marginally better than the response time model, except the ', 'error rate of the osg model was significantly better. ', 'in figure 3, the selected w2v model slightly outperforms ', 'the osg model in mid-range true positive rates, while ', 'the osg model performed slightly better in a higher true ', 'positive area. precision and recall curves show similar ', 'patterns to those we observed from the immediate post-test ', 'prediction models. the osg model only outperforms the ', 'w2v model in a very low recall value area. ', ' ', '4.1.3 comparing models ', 'compared to the selected w2v model in the immediate ', 'post-test condition, the selected w2v model in the delayed ', 'post-test retention condition showed a significantly lower ', 'auc score, marginally higher f1 score, and marginally ', 'higher error rate. in terms of osg models, the selected osg ', 'model for delayed post-test retention showed a significantly ', 'better f1 score and error rates than the selected osg model ', 'in the immediate post-test condition. based on these results, ', 'we can argue that osgood scale scores can be more useful for ', 'predicting student retention in the delayed post-test session ', 'than predicting the outcome from the immediate post-test. ', 'in terms of selected feature types, the best-performing ', 'osg models used features based on the difference between ', 'responses (resp) or the convex hull area (chull ) that was ', 'created from the relative location of the responses. on the ', 'other hand, selected w2v models used both the distance ', 'between the target word and responses and difference ', 'between responses (dist+resp). ', 'when we compared ', 'both w2v and osg models using the difference between ', 'responses feature, we found that performance is similar in ', 'the immediate post-test data. however, the osg model ', 'was significantly better in the delayed post-test data. these ', 'results show that osgood scale scores can be more useful for ', 'representing the relationship among response sequences. ', ' ', '4.2 comparing the osgood scales ', ' ', 'to identify which osgood scales are more helpful than ', 'others for predicting students’ performance, we conducted ', 'a scale-wise importance analysis. the results from this ', 'section reveal which osgood scales are more important than ', 'others, and how the performance of prediction models with ', 'a reduced number of scales is comparable with the full-scale ', 'model. ', ' ', '4.2.1 ', ' ', 'identifying more important osgood scales ', ' ', 'in this section, based on the selected osgood score model ', 'from section 4.1, we identified the level of contribution for ', 'features based on each osgood scale. for example, the ', 'selected osg model for predicting the immediate post-test ', 'data uses the difference between responses in ten osgood ', 'scales as features. in order to diagnose the importance level ', 'of the first scale (bad–good ), we can retrain the model with ', 'features based on the nine other scales and compare the85 ', ' ', '\\\\x0ctable 2: ranks of predictive feature sets for regular word2vec models (w2v) and osgood score models ', '(osg) in the immediate post-test data. all models are significantly better than the baseline model. (bold: ', 'the selected model with highest overall rank.) ', 'features ', 'baseline ', 'rt ', 'dist ', 'resp ', 'chull ', 'dist+resp ', 'dist+chull ', ' ', 'auc ', '0.68 [0.67, 0.69] (5) ', '0.69 [0.68, 0.70] (4) ', '0.72 [0.71, 0.74] (1) ', '0.70 [0.69, 0.71] (3) ', 'na ', '0.72 [0.71, 0.73] (2) ', 'na ', ' ', 'w2v models ', 'f1 ', '0.74 [0.73, 0.74] (5) ', '0.75 [0.75, 0.76] (3) ', '0.76 [0.75, 0.76] (2) ', '0.75 [0.74, 0.76] (4) ', 'na ', '0.76 [0.75, 0.77] (1) ', 'na ', ' ', 'err ', '0.33 [0.33, 0.34] (5) ', '0.31 [0.31, 0.32] (4) ', '0.29 [0.28, 0.30] (2) ', '0.31 [0.30, 0.32] (3) ', 'na ', '0.29 [0.28, 0.30] (1) ', 'na ', ' ', 'auc ', '0.68 [0.67, 0.69] (5) ', '0.69 [0.68, 0.70] (2) ', '0.67 [0.66, 0.68] (7) ', '0.69 [0.68, 0.70] (1) ', '0.69 [0.68, 0.70] (3) ', '0.68 [0.67, 0.69] (4) ', '0.67 [0.66, 0.68] (6) ', ' ', 'osg models ', 'f1 ', '0.74 [0.73, 0.74] (5) ', '0.75 [0.74, 0.76] (2) ', '0.73 [0.73, 0.74] (7) ', '0.75 [0.75, 0.76] (1) ', '0.74 [0.73, 0.75] (4) ', '0.74 [0.73, 0.75] (3) ', '0.74 [0.73, 0.74] (6) ', ' ', 'err ', '0.33 [0.33, 0.34] (7) ', '0.31 [0.31, 0.32] (2) ', '0.33 [0.32, 0.34] (6) ', '0.31 [0.30, 0.32] (1) ', '0.32 [0.31, 0.33] (4) ', '0.31 [0.31, 0.32] (3) ', '0.33 [0.32, 0.34] (5) ', ' ', 'table 3: ranks of predictive feature sets for w2v and osg models in the delayed post-test data. all models ', 'are significantly better than the baseline model. (bold: the selected model with highest overall rank.) ', 'features ', 'baseline ', 'rt ', 'dist ', 'resp ', 'chull ', 'dist+resp ', 'dist+chull ', ' ', 'auc ', '0.65 [0.64, 0.67] (5) ', '0.67 [0.65, 0.68] (3) ', '0.66 [0.64, 0.68] (4) ', '0.69 [0.67, 0.71] (1) ', 'na ', '0.68 [0.66, 0.70] (2) ', 'na ', ' ', 'w2v models ', 'f1 ', '0.75 [0.74, 0.76] (5) ', '0.76 [0.76, 0.77] (4) ', '0.77 [0.76, 0.78] (3) ', '0.77 [0.76, 0.78] (2) ', 'na ', '0.78 [0.77, 0.79] (1) ', 'na ', ' ', 'err ', '0.33 [0.32, 0.34] (5) ', '0.31 [0.30, 0.32] (3) ', '0.31 [0.30, 0.32] (4) ', '0.30 [0.29, 0.31] (2) ', 'na ', '0.30 [0.29, 0.31] (1) ', 'na ', ' ', 'performance of the newly trained model with the existing ', 'full-scale model. ', 'in table 4, we picked the top five scales that were ', 'important in individual prediction tasks. we found that bigsmall, helpful-harmful, complex-simple, and fast-slow were ', 'commonly important osgood scales for predicting students’ ', 'performance in immediate post-test and delayed post-test ', 'sessions. scales like bad-good and passive-active were only ', 'important scales in the immediate post-test prediction. ', 'likewise, new-old was an important scale only in the delayed ', 'post-test prediction. ', 'table 4: scale-wise importance of each osgood ', 'scale. scales were selected based on the sum of each ', 'evaluation metric’s rank. (bold: osgood scales that ', 'were commonly important in both prediction tasks; ', '*: top five scales in each prediction task including ', 'tied ranks) ', 'scales ', 'bad-good ', 'passive-active ', 'powerful-helpless ', 'big-small ', 'helpful-harmful ', 'complex-simple ', 'fast-slow ', 'noisy-quiet ', 'new-old ', 'healthy-sick ', ' ', '4.2.2 ', ' ', 'imm. post-test ', 'auc f1 err all ', '1 ', '1 ', '1 ', '1* ', '2 ', '4 ', '3 ', '2* ', '7 ', '9 ', '6 ', '7.5 ', '3 ', '3 ', '4 ', '3* ', '4 ', '6 ', '5 ', '5.5* ', '8 ', '5 ', '2 ', '5.5* ', '5 ', '2 ', '7 ', '4* ', '6 ', '8 ', '8 ', '7.5 ', '9 ', '7 ', '9 ', '9 ', '10 ', '10 10 ', '10 ', ' ', 'del. post-test ', 'auc f1 err all ', '4 ', '10 4 ', '6 ', '8 ', '6 ', '6 ', '7 ', '10 ', '8 ', '10 ', '10 ', '1 ', '3 ', '2 ', '2* ', '2 ', '1 ', '1 ', '1* ', '3 ', '5 ', '7 ', '4.5* ', '6 ', '4 ', '3 ', '3* ', '7 ', '9 ', '9 ', '9 ', '5 ', '2 ', '8 ', '4.5* ', '9 ', '7 ', '5 ', '8 ', ' ', 'performance of reduced models ', ' ', 'based on the scale-wise importance analysis results, we built ', 'reduced-scale models that only contain features with more ', 'important osgood scales. the prediction performance of ', 'reduced-scale models was similar or marginally better than ', 'full-scale osg models. for example, the osg model for ', 'predicting the immediate post-test outcome with the top ', 'two scales (bad–good and passive–active) were marginally ', 'better than the full-scale model (auc: 0.71 [0.70, 0.72], f1 : ', '0.76 [0.75, 0.77], error rate: 0.30 [0.29, 0.30]). similar results ', 'were observed for predicting retention in the delayed posttest (selected scales: helpful–harmful, big–small ) (auc: 0.71 ', '[0.69, 0.72], f1 : 0.79 [0.78, 0.80], error rate: 0.28 [0.27, ', ' ', 'auc ', '0.65 [0.64, 0.67] (5) ', '0.67 [0.65, 0.68] (3) ', '0.66 [0.64, 0.68] (4) ', '0.63 [0.61, 0.65] (7) ', '0.69 [0.68, 0.71] (1) ', '0.64 [0.62, 0.66] (6) ', '0.69 [0.67, 0.71] (2) ', ' ', 'osg models ', 'f1 ', '0.75 [0.74, 0.76] (7) ', '0.76 [0.76, 0.77] (5) ', '0.78 [0.77, 0.79] (3) ', '0.76 [0.75, 0.77] (6) ', '0.78 [0.77, 0.79] (2) ', '0.77 [0.76, 0.78] (4) ', '0.78 [0.78, 0.79] (1) ', ' ', 'err ', '0.33 [0.32, 0.34] (7) ', '0.31 [0.30, 0.32] (5) ', '0.30 [0.29, 0.31] (3) ', '0.32 [0.31, 0.33] (6) ', '0.28 [0.27, 0.29] (1) ', '0.31 [0.29, 0.32] (4) ', '0.29 [0.27, 0.30] (2) ', ' ', '0.29]). although differences were small, the results indicate ', 'that using a small number of osgood scales can be similarly ', 'effective to the full-scale model. ', ' ', '5. ', ' ', 'discussion and conclusions ', ' ', 'in this paper, we introduced a novel semantic similarity ', 'scoring method that uses predefined semantic scales to ', 'represent the relationship between words. by combining ', 'osgood’s semantic scales [16] and word2vec [13], we could ', 'automatically extract the semantic relationship between ', 'two words in a more interpretable manner. to show this ', 'method can effectively represent students’ knowledge in ', 'vocabulary acquisition, we built prediction models that can ', 'be used to predict the student’s immediate learning and ', 'long-term retention. we found that our models performed ', 'significantly better than the baseline and the responsetime-based models. in the future, we believe results from ', 'using an osgood scale-based student model could be used ', 'to provide a more personalized learning experience, such ', 'as generating questions that can improve an individual ', 'student’s understanding for specific semantic attributes. ', 'based on our findings, we have identified the following ', 'points for further discussion. first, in section 4.1, we ', 'found that models using osgood scale scores perform ', 'similarly with models using regular word2vec scores ', 'for predicting students’ long-term retention of acquired ', 'vocabulary. however, we think our models can be further ', 'improved by incorporating additional features. for example, ', 'non-semantic score-based features like response time and ', 'orthographic similarity among responses can be useful ', 'features for capturing different patterns of false predictions ', 'of current models. moreover, some general measures to ', 'capture a student’s meta-cognitive or linguistic skills could ', 'be helpful to explain different retention results found even if ', 'students provided the same response sequences. similarly, in ', 'section 4.1.3, we found that osgood scores can be a better ', 'metric to characterize the relationship between responses ', 'in terms of predicting students’ retention. a composite ', 'model that uses both regular word2vec score-based feature ', '(target-response distance) and osgood scale score-based ', 'feature (response-response distance) may also provide better86 ', ' ', '\\\\x0cfigure 3: roc curves and precision and recall curves for selected immediate post-test prediction models ', '(left) and delayed post-test prediction models (right). curves are smoothed out with a local polynomial ', 'regression method based on repeated cross-validation results. ', ' ', 'prediction performance. ', 'second, we found that models with a reduced number of ', 'osgood scales performed marginally better than the fullscale model. however, differences were very small. since ', 'this study only used some of the semantic scales from ', 'osgood’s study [16], further investigation would be required ', 'to examine the validity of these scales, including other scales ', 'not used for this study, for capturing the semantic attributes ', 'of student responses during vocabulary learning. ', 'also, there were some limitations in the current study ', 'and areas for future work. first, expanding the scope ', 'of analysis to the full set of experimental conditions ', 'used in the study may reveal more complex interactions ', 'between these conditions and students’ short- and longterm learning. second, this study used a fixed threshold ', 'of 0.5 for investigating false prediction results. however, an ', 'optimal threshold for each participant group or prediction ', 'model could be selected, especially if there are different false ', 'positive or negative patterns observed for different groups ', 'of students. lastly, this study collected data from a single ', 'vocabulary tutoring system that was used in a classroom ', 'setting. applying the proposed method to data that was ', 'collected from a non-classroom setting or other vocabulary ', 'learning system would be useful to show the generalization ', 'of our suggested method. ', ' ', '6. ', ' ', 'acknowledgments ', ' ', 'the research reported here was supported by the institute of ', 'education sciences, u.s. department of education, through ', 'grant r305a140647 to the university of michigan. the ', 'opinions expressed are those of the authors and do not ', 'represent views of the institute or the u.s. department ', 'of education. we thank dr. charles perfetti and his lab ', 'team at the university of pittsburgh, particularly adeetee ', 'bhide and kim muth, and the helpful personnel at all of our ', 'partner schools. ', ' ', '7. ', ' ', 'references ', ' ', '[1] s. adlof, g. frishkoff, j. dandy, and c. perfetti. effects of ', 'induced orthographic and semantic knowledge on ', 'subsequent learning: a test of the partial knowledge ', 'hypothesis. reading and writing, 29(3):475–500, 2016. ', '[2] j. e. beck. engagement tracing: using response times to ', 'model student disengagement. artificial intelligence in ', 'education: supporting learning through intelligent and ', 'socially informed technology, 125:88, 2005. ', '[3] k. collins-thompson and j. callan. automatic and human ', 'scoring of word definition responses. in hlt-naacl, ', 'pages 476–483, 2007. ', '[4] m. coltheart. the mrc psycholinguistic database. the ', ' ', '[5] ', '[6] ', '[7] ', ' ', '[8] ', ' ', '[9] ', ' ', '[10] ', '[11] ', ' ', '[12] ', '[13] ', ' ', '[14] ', '[15] ', '[16] ', '[17] ', ' ', '[18] ', '[19] ', ' ', '[20] ', ' ', 'quarterly journal of experimental psychology, ', '33(4):497–505, 1981. ', 'e. dale. vocabulary measurement: techniques and major ', 'findings. elementary english, 42(8):895–948, 1965. ', 'f. t. durso and w. j. shore. partial knowledge of word ', 'meanings. journal of experimental psychology: general, ', '120(2):190, 1991. ', 'g. a. frishkoff, k. collins-thompson, l. hodges, and ', 's. crossley. accuracy feedback improves word learning ', 'from context: evidence from a meaning-generation task. ', 'reading and writing, 29(4):609–632, 2016. ', 'g. a. frishkoff, k. collins-thompson, s. nam, l. hodges, ', 'and s. a. crossley. dynamic support of contextual ', 'vocabulary acquisition for reading (dscovar): an ', 'intelligent tutoring system for contextual word learning. ', 'handbook on educational technologies for literacy, 2016. ', 'g. a. frishkoff, c. a. perfetti, and k. collins-thompson. ', 'predicting robust vocabulary growth from measures of ', 'incremental learning. scientific studies of reading, ', '15(1):71–91, 2011. ', 't. k. landauer. latent semantic analysis. wiley online ', 'library, 2006. ', 'y. li, l. xu, f. tian, l. jiang, x. zhong, and e. chen. ', 'word embedding revisited: a new representation learning ', 'and explicit matrix factorization perspective. in ', 'proceedings of the 24th international joint conference on ', 'artificial intelligence, buenos aires, argentina, pages ', '3650–3656, 2015. ', 'y. ma, l. agnihotri, m. h. education, r. baker, and ', 's. mojarad. effect of student ability and question difficulty ', 'on duration. in educational data mining, 2016. ', 't. mikolov, i. sutskever, k. chen, g. s. corrado, and ', 'j. dean. distributed representations of words and phrases ', 'and their compositionality. in advances in neural ', 'information processing systems, pages 3111–3119, 2013. ', 'g. a. miller. wordnet: a lexical database for english. ', 'communications of the acm, 38(11):39–41, 1995. ', 's. nam. predicting off-task behaviors in an adaptive ', 'vocabulary learning system. in educational data mining, ', '2016. ', 'c. e. osgood, g. j. suci, and p. h. tannenbaum. the ', 'measurement of meaning. university of illinois press, 1957. ', 'k. ostrow, c. donnelly, s. adjei, and n. heffernan. ', 'improving student modeling through partial credit and ', 'problem difficulty. in proc. of the second acm conference ', 'on learning@scale, pages 11–20. acm, 2015. ', 'p. i. pavlik and j. r. anderson. practice and forgetting ', 'effects on vocabulary memory: an activation-based model ', 'of the spacing effect. cog. science, 29(4):559–586, 2005. ', 'e. g. van inwegen, s. a. adjei, y. wang, and n. t. ', 'heffernan. using partial credit and response history to ', 'model user knowledge. international educational data ', 'mining society, 2015. ', 'l. m. yonek. the effects of rich vocabulary instruction ', 'on students’ expository writing. phd thesis, university of ', 'pittsburgh, 2008.']\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) replace carriage returns (i.e., \"\\n\") with a white space\n",
    "# check that the result looks okay by printing the \n",
    "# first 1000 characters of the 1st doc:\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "spaced_documents = []\n",
    "\n",
    "for document in clean_documents:\n",
    "    spaced_document = (str(document)).replace(r'\\n', ' ')\n",
    "    spaced_documents.append(spaced_document)\n",
    "\n",
    "spaced_documents[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['semantic score-based features ', ' ', 'we now describe the semantic features tested in our ', 'prediction models. ', ' ', '3.2.1 ', ' ', 'semantic scales ', ' ', 'for this study, we used semantic scales from osgood’s study ', '[16]. ten scales were selected by a cognitive psychologist as ', 'being considered semantic attributes that can be detected ', 'during word learning (figure 2). each semantic scale ', 'consists of pairs of semantic attributes. for example, the ', 'bad–good scale can show how the meaning of a word can ', 'be projected on a scale with bad and good located at either ', ' ', 'basic semantic distance scores ', ' ', 'to extract meaningful semantic information, we have ', 'applied the following measures that can be used to explain ', 'various characteristics of student responses for different ', 'target words. in this study, we used a pre-trained model ', 'for word2vec,1 built based on the google news corpus ', '(100 billion tokens with 3 million unique vocabularies, \n"
     ]
    }
   ],
   "source": [
    "# 6) replace the punctation below by a white space\n",
    "# check that the result looks okay \n",
    "# (e.g., by print the first 1000 characters of the 1st doc)\n",
    "\n",
    "punctuation = ['.', '...', '!', '#', '\"', '%', '$', \"'\", '&', ')', \n",
    "               '(', '+', '*', '-', ',', '/', '.', ';', ':', '=', \n",
    "               '<', '?', '>', '@', '\",', '\".', '[', ']', '\\\\', ',',\n",
    "               '_', '^', '`', '{', '}', '|', '~', '−', '”', '“', '’']\n",
    "\n",
    "document_no_punctuation = []\n",
    "\n",
    "for document in spaced_documents:\n",
    "    for character in punctuation:\n",
    "        document.replace(character,' ')\n",
    "    document_no_punctuation.append(document)\n",
    "        \n",
    "print(document_no_punctuation[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['semantic score-based features ', ' ', 'we now describe the semantic features tested in our ', 'prediction models. ', ' ', '3.2.1 ', ' ', 'semantic scales ', ' ', 'for this study, we used semantic scales from osgood’s study ', '[16]. ten scales were selected by a cognitive psychologist as ', 'being considered semantic attributes that can be detected ', 'during word learning (figure 2). each semantic scale ', 'consists of pairs of semantic attributes. for example, the ', 'bad–good scale can show how the meaning of a word can ', 'be projected on a scale with bad and good located at either ', ' ', 'basic semantic distance scores ', ' ', 'to extract meaningful semantic information, we have ', 'applied the following measures that can be used to explain ', 'various characteristics of student responses for different ', 'target words. in this study, we used a pre-trained model ', 'for word2vec,1 built based on the google news corpus ', '(100 billion tokens with 3 million unique vocabularies, \n"
     ]
    }
   ],
   "source": [
    "# 7) remove numbers by either a white space or the word \"number\"\n",
    "# again, print the first 1000 characters of the first document\n",
    "# to check that you're doing the right thing\n",
    "\n",
    "numbers = ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "\n",
    "document_no_numbers = []\n",
    "\n",
    "for document in document_no_punctuation:\n",
    "    for character in numbers:\n",
    "        document.replace(character,' ')\n",
    "    document_no_numbers.append(document)\n",
    "        \n",
    "print(document_no_numbers[0][:1000])\n",
    "    \n",
    "       \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['semantic score-based features ', ' ', 'we now describe the semantic features tested in our ', 'prediction models. ', ' ', '3.2.1 ', ' ', 'semantic scales ', ' ', 'for this study, we used semantic scales from osgood’s study ', '[16]. ten scales were selected by a cognitive psychologist as ', 'being considered semantic attributes that can be detected ', 'during word learning (figure 2). each semantic scale ', 'consists of pairs of semantic attributes. for example, the ', 'bad–good scale can show how the meaning of a word can ', 'be projected on a scale with bad and good located at either ', ' ', 'basic semantic distance scores ', ' ', 'to extract meaningful semantic information, we have ', 'applied the following measures that can be used to explain ', 'various characteristics of student responses for different ', 'target words. in this study, we used a pre-trained model ', 'for word2vec,1 built based on the google news corpus ', '(100 billion tokens with 3 million unique vocabularies, \n"
     ]
    }
   ],
   "source": [
    "# 8) Remove the stop words below from our documents\n",
    "# print the first 1000 characters of the first document\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', \n",
    "              'ourselves', 'you', 'your', 'yours', 'yourself', \n",
    "              'yourselves', 'he', 'him', 'his', 'himself', 'she', \n",
    "              'her', 'hers', 'herself', 'it', 'its', 'itself', \n",
    "              'they', 'them', 'their', 'theirs', 'themselves', \n",
    "              'what', 'which', 'who', 'whom', 'this', 'that', \n",
    "              'these', 'those', 'am', 'is', 'are', 'was', 'were', \n",
    "              'be', 'been', 'being', 'have', 'has', 'had', 'having', \n",
    "              'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', \n",
    "              'but', 'if', 'or', 'because', 'as', 'until', 'while', \n",
    "              'of', 'at', 'by', 'for', 'with', 'about', 'against', \n",
    "              'between', 'into', 'through', 'during', 'before', \n",
    "              'after', 'above', 'below', 'to', 'from', 'up', 'down', \n",
    "              'in', 'out', 'on', 'off', 'over', 'under', 'again', \n",
    "              'further', 'then', 'once', 'here', 'there', 'when', \n",
    "              'where', 'why', 'how', 'all', 'any', 'both', 'each', \n",
    "              'few', 'more', 'most', 'other', 'some', 'such', 'no', \n",
    "              'nor', 'not', 'only', 'own', 'same', 'so', 'than', \n",
    "              'too', 'very', 's', 't', 'can', 'will', \n",
    "              'just', 'don', 'should', 'now']\n",
    "\n",
    "\n",
    "document_no_stop_words = []\n",
    "\n",
    "for document in document_no_numbers:\n",
    "    for word in stop_words:\n",
    "        document.replace(word,'')\n",
    "    document_no_stop_words.append(document)\n",
    "        \n",
    "print(document_no_stop_words[0][:1000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['semantic score-based features ', ' ', 'we now describe the semantic features tested in our ', 'prediction models. ', ' ', '3.2.1 ', ' ', 'semantic scales ', ' ', 'for this study, we used semantic scales from osgood’s study ', '[16]. ten scales were selected by a cognitive psychologist as ', 'being considered semantic attributes that can be detected ', 'during word learning (figure 2). each semantic scale ', 'consists of pairs of semantic attributes. for example, the ', 'bad–good scale can show how the meaning of a word can ', 'be projected on a scale with bad and good located at either ', ' ', 'basic semantic distance scores ', ' ', 'to extract meaningful semantic information, we have ', 'applied the following measures that can be used to explain ', 'various characteristics of student responses for different ', 'target words. in this study, we used a pre-trained model ', 'for word2vec,1 built based on the google news corpus ', '(100 billion tokens with 3 million unique vocabularies, \n"
     ]
    }
   ],
   "source": [
    "# 9) remove words with one and two characters (e.g., 'd', 'er', etc.)\n",
    "# print the first 1000 characters of the first document\n",
    "\n",
    "import re\n",
    "\n",
    "for document in document_no_stop_words:   \n",
    "     document.join(word for word in document.split() if len(word)>2)\n",
    "\n",
    "print(document_no_stop_words[0][:1000])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) package all of your work above into a function that cleans a given document\n",
    "\n",
    "def clean_list_of_documents(documents):\n",
    "    \n",
    "    cleaned_docs = []\n",
    "\n",
    "    ### your code ###\n",
    "        \n",
    "    return cleaned_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11a) reimport your raw data using the code in 2)\n",
    "documents = []\n",
    "\n",
    "        \n",
    "# 11b) clean your files using the function above\n",
    "\n",
    "\n",
    "# 11c) print the first 1000 characters of the first document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Build your list of vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list of words (i.e., the vocabulary) is going to become the columns of your matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Describe why we need to figure out the vocabulary used in our corpus (refer back to Sherin's paper, and explain in your own words): To see what patterns of words people use to explain scientific phenomenon (which tells us about how these concepts are taught, how they are interpreted and how people ultimately reationalize them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) create a function that takes in a list of documents\n",
    "# and returns a set of unique words. Make sure that you\n",
    "# sort the list alphabetically before returning it. \n",
    "\n",
    "def get_vocabulary(documents):\n",
    "    voc = []\n",
    "    \n",
    "    ### your code ###\n",
    "    \n",
    "    return voc\n",
    "\n",
    "# Then print the length of your vocabulary (it should be \n",
    "# around 5500 words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) what was the size of Sherin's vocabulary? \n",
    "647 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - transform your documents into 100-words chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15) create a function that takes in a list of documents\n",
    "# and returns a list of 100-words chunk \n",
    "# (with a 25 words overlap between them)\n",
    "# Optional: add two arguments, one for the number of words\n",
    "# in each chunk, and one for the overlap size\n",
    "# Advice: combining all the documents into one giant string\n",
    "# and splitting it into separate words will make your life easier!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16) create a for loop to double check that each chunk has \n",
    "# a length of 100\n",
    "# Optional: use assert to do this check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17) print the first chunk, and compare it to the original text.\n",
    "# does that match what Sherin describes in his paper?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18) how many chunks did Sherin have? What does a chunk become \n",
    "# in the next step of our topic modeling algorithm? \n",
    "\n",
    "794 chunks of text\n",
    "Each gets mapped on to a vector of 647 numbers (representing the unique words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19) what are some other preprocessing steps we could do \n",
    "# to improve the quality of the text data? Mention at least 2.\n",
    "\n",
    "1. Find some technique to give significance to the order of words\n",
    "2. Make a second list of common words (beyond the most obvious ones) to identify 'unique words' even better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20) in your own words, describe the next steps of the \n",
    "# data modeling algorithms (listed below):\n",
    "\n",
    "The 794 vectors are clustered based on similarity/deviance. Centroid clustering is used since it is simplest and brings\n",
    "together vectors with the most in common (geometrically/content-wise). We play around with different clusters numbers and\n",
    "sizes to get an optimal configuration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Vector and Matrix operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Weight word frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Matrix normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 - Deviation Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 - Visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Step - Putting it all together: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in python code, our goal is to recreate the steps above as functions\n",
    "# so that we can just one line to run topic modeling on a list of \n",
    "# documents: \n",
    "def ExtractTopicsVSM(documents, numTopics):\n",
    "    ''' this functions takes in a list of documents (strings), \n",
    "        runs topic modeling (as implemented by Sherin, 2013)\n",
    "        and returns the clustering results, the matrix used \n",
    "        for clustering a visualization '''\n",
    "    \n",
    "    # step 2: clean up the documents\n",
    "    documents = clean_list_of_documents(documents)\n",
    "    \n",
    "    # step 3: let's build the vocabulary of these docs\n",
    "    vocabulary = get_vocabulary(documents)\n",
    "    \n",
    "    # step 4: we build our list of 100-words overlapping fragments\n",
    "    documents = flatten_and_overlap(documents)\n",
    "    \n",
    "    # step 5: we convert the chunks into a matrix\n",
    "    matrix = docs_by_words_matrix(documents, vocabulary)\n",
    "    \n",
    "    # step 6: we weight the frequency of words (count = 1 + log(count))\n",
    "    matrix = one_plus_log_mat(matrix, documents, vocabulary)\n",
    "    \n",
    "    # step 7: we normalize the matrix\n",
    "    matrix = normalize(matrix)\n",
    "    \n",
    "    # step 8: we compute deviation vectors\n",
    "    matrix = transform_deviation_vectors(matrix, documents)\n",
    "    \n",
    "    # step 9: we apply a clustering algorithm to find topics\n",
    "    results_clustering = cluster_matrix(matrix)\n",
    "    \n",
    "    # step 10: we create a visualization of the topics\n",
    "    visualization = visualize_clusters(results_clustering, vocabulary)\n",
    "    \n",
    "    # finally, we return the clustering results, the matrix, and a visualization\n",
    "    return results_clustering, matrix, visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
